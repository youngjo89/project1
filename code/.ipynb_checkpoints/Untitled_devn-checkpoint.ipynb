{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 store에서 units이 모두 0인 item_nbr은 날린다..\n",
    "    - 계산량을 줄이기 위해서\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('../data/key.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "weather = pd.read_csv('../data/weather.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_ = weather.drop(['date', 'codesum'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_.at[0, 'sunrise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = list(weather_.columns)\n",
    "col_list = col_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num in range(len(weather_)) :\n",
    "    for col in col_list :\n",
    "        if 'M' in weather_.at[num, col] or 'T' in weather_.at[num, col] or '-' in weather_.at[num, col] :\n",
    "            weather_.set_value(num, col, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TM_transform(series, T_replace, M_replace): \n",
    "    \"\"\"\n",
    "    데이터내의 T, M을 원하는 값으로 바꿔주는 함수\n",
    "    TM_transform(series, T_replace, M_replace)\n",
    "    \"\"\"\n",
    "    series = series.astype(str).map(lambda s: s.strip())\n",
    "    series[series == 'T'] = T_replace\n",
    "    series[series =='M'] = M_replace\n",
    "    return series.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_dateformat(df, year):\n",
    "    \"\"\"\n",
    "    영문 월을 숫자 월로 바꾸어주고 나중에 사용하기 쉽도록 datetime.date 형태로 바꾸어주는 함수\n",
    "    \"\"\"\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    for i in range(len(df)):\n",
    "        dates = df.loc[i][0]\n",
    "        dates = dates.split(\" \")\n",
    "        for j in range(len(months)):\n",
    "            if dates[0] == months[j]:\n",
    "                dates[0] = str(j + 1)\n",
    "                dates_df = [\"{} {} {}\".format(year, dates[0], dates[1])]\n",
    "                dates_df = pd.to_datetime(dates_df)\n",
    "                df.loc[i][0] = dates_df.date[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_holiday(holiday_df1, holiday_df2, holiday_df3):\n",
    "    \"\"\"\n",
    "    각 연도별 공휴일 리스트 합치기\n",
    "    \"\"\"\n",
    "    frame = [holiday_df1, holiday_df2, holiday_df3]\n",
    "    holiday = pd.concat(frame).reset_index(drop=True)\n",
    "    return holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_holiday(file, year):\n",
    "    \"\"\"\n",
    "    수요에 영향을 미치는 주요 공휴일을 찾아내는 함수\n",
    "    \"\"\"\n",
    "    holidays = [\"New Year's Day\", \"Martin Luther King Jr. Day\", \"Valentine's Day\",  \"President's Day\", \"Easter Sunday\", \n",
    "                      \"Mother's Day\", \"Memorial Day\", \"Father's Day\", \"Independence Day\", \"Labor Day\", \"Columbus Day\",\n",
    "                      \"Halloween\", \"Veterans Day\", \"Thanksgiving Day\", \"Black Friday\", \"Christmas Eve\", \"Christmas Day\", \"New Year's Eve\"]\n",
    "    \n",
    "    holi = pd.read_excel(file, year, header=None)\n",
    "    holi = match_dateformat(holi, year)\n",
    "    holiday = pd.DataFrame(columns=[0,1,2,3,4])\n",
    "    for _ in holidays:\n",
    "        for i in range(len(holi[2])):\n",
    "            if _ == holi[2][i]:\n",
    "                holiday = holiday.append(holi.loc[i])\n",
    "    return holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(df, holiday):\n",
    "    \"\"\"\n",
    "    train데이터를 가공하는 함수\n",
    "    \"\"\"\n",
    "#     df['units'] = np.log(df['units'] + 1)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "    df['weekend'] = df.date.dt.weekday.isin([5, 6])  # 5: 토요일, 6: 일요일\n",
    "\n",
    "    df['holiday'] = df.date.isin(holiday[0])\n",
    "    df['weekday_holiday'] = df.holiday & (df.weekend == False)\n",
    "    df['weekend_holiday'] = df.holiday & df.weekend\n",
    "\n",
    "    # There are values that are computed as being \"normal\" for a given location. Normal are computed based on 30 years worth of data every ten years. (today temp - normal) = depart\n",
    "    weather['date'] = pd.to_datetime(weather['date']) #weather는 글로벌변수\n",
    "    for i in range(len(weather['codesum'])):\n",
    "        codesum = weather['codesum'][i].split(\" \")\n",
    "        for _ in codesum:\n",
    "            if _ == 'RA':\n",
    "                weather.set_value(i, 'rain_flag', 1)\n",
    "            elif _ == 'SN':\n",
    "                weather.set_value(i, 'snow_flag', 1)\n",
    "            elif _ == \"\":\n",
    "                weather.set_value(i, 'normal_flag', 1)\n",
    "            else:\n",
    "                weather.set_value(i, 'abnormal_flag', 1)\n",
    "\n",
    "    # return x or y depending on the condition\n",
    "    # \"For the purposes of this competition, we have defined a weather event as any day in which more than an inch of rain or two inches of snow was observed.\"\n",
    "    # weather_event =  (((codesum contains SN) and (snowfall > 2)) or ((codesum contains RA) and (preciptotal > 1)))\n",
    "    weather['preciptotal'] = TM_transform(weather['preciptotal'], 0.005, 0.00)\n",
    "    weather['snowfall'] = TM_transform(weather['snowfall'], 0.005, 0.00)\n",
    "    weather['snow_event'] = np.where(np.where(weather['snow_flag'] == 1, 1, 0) + np.where(weather['snowfall'] > 2, 1, 0) == 2, 1, 0)\n",
    "    weather['rain_event'] = np.where(np.where(weather['rain_flag'] == 1, 1, 0) + np.where(weather['preciptotal'] > 1, 1, 0) == 2, 1, 0)\n",
    "    weather['event'] = weather['snow_event'] + weather['rain_event']\n",
    "    \n",
    "\n",
    "#    weather['preciptotal_flag'] = np.where(weather['preciptotal'] > 0.2, 1, 0)\n",
    "#     weather['depart'] = TM_transform(weather['depart'], np.nan, 0.00)\n",
    "#     weather['depart_flag'] = np.where(weather['depart'] > 8.0, 1, 0)\n",
    "#     weather['depart_flag'] = np.where(weather['depart'] < 8.0, -1, 0)\n",
    "    \n",
    "    df = pd.merge(df, key, on='store_nbr') #key는 글로벌 변수\n",
    "    \n",
    "    df = pd.merge(df, weather[['date', 'station_nbr', 'rain_flag', 'snow_flag', 'normal_flag', 'event']], on=['date', 'station_nbr'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing2(df, holiday):\n",
    "    \"\"\"\n",
    "    train데이터를 가공하는 함수\n",
    "    \"\"\"\n",
    "#     df['units'] = np.log(df['units'] + 1)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "    df['weekend'] = df.date.dt.weekday.isin([5, 6])  # 5: 토요일, 6: 일요일\n",
    "\n",
    "    df['holiday'] = df.date.isin(holiday[0])\n",
    "\n",
    "    # return x or y depending on the condition\n",
    "    # \"For the purposes of this competition, we have defined a weather event as any day in which more than an inch of rain or two inches of snow was observed.\"\n",
    "    # weather_event =  (((codesum contains SN) and (snowfall > 2)) or ((codesum contains RA) and (preciptotal > 1)))\n",
    "    weather['preciptotal'] = TM_transform(weather['preciptotal'], 0.005, np.NaN)\n",
    "    weather['snowfall'] = TM_transform(weather['snowfall'], 0.005, np.NaN)\n",
    "#     weather['snow_event'] = np.where(np.where(weather['snow_flag'] == 1, 1, 0) + np.where(weather['snowfall'] > 2, 1, 0) == 2, 1, 0)\n",
    "#     weather['rain_event'] = np.where(np.where(weather['rain_flag'] == 1, 1, 0) + np.where(weather['preciptotal'] > 1, 1, 0) == 2, 1, 0)\n",
    "    weather['event'] = \"\"\n",
    "    \n",
    "    for num in range(len(df)) :\n",
    "        if weather.at[num, 'snowfall'] >= 2 or weather.at[num, 'preciptotal'] >= 1 :\n",
    "            weather.set_value(num, 'event', 1)\n",
    "        else :\n",
    "            weather.set_value(num, 'event', 0)\n",
    "    \n",
    "\n",
    "#    weather['preciptotal_flag'] = np.where(weather['preciptotal'] > 0.2, 1, 0)\n",
    "#     weather['depart'] = TM_transform(weather['depart'], np.nan, 0.00)\n",
    "#     weather['depart_flag'] = np.where(weather['depart'] > 8.0, 1, 0)\n",
    "#     weather['depart_flag'] = np.where(weather['depart'] < 8.0, -1, 0)\n",
    "    \n",
    "    df = pd.merge(df, key, on='store_nbr') #key는 글로벌 변수\n",
    "    \n",
    "    df = pd.merge(df, weather[['date', 'station_nbr', 'event']], on=['date', 'station_nbr'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing3(df, holiday):\n",
    "    \"\"\"\n",
    "    train데이터를 가공하는 함수\n",
    "    \"\"\"\n",
    "#     df['units'] = np.log(df['units'] + 1)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "    df['weekend'] = df.date.dt.weekday.isin([5, 6])  # 5: 토요일, 6: 일요일\n",
    "\n",
    "    df['holiday'] = df.date.isin(holiday[0])\n",
    "    df['weekday_holiday'] = df.holiday & (df.weekend == False)\n",
    "    df['weekend_holiday'] = df.holiday & df.weekend\n",
    "\n",
    "    # There are values that are computed as being \"normal\" for a given location. Normal are computed based on 30 years worth of data every ten years. (today temp - normal) = depart\n",
    "    weather['date'] = pd.to_datetime(weather['date']) #weather는 글로벌변수\n",
    "    for i in range(len(weather['codesum'])):\n",
    "        codesum = weather['codesum'][i].split(\" \")\n",
    "        for _ in codesum:\n",
    "            if _ == 'RA':\n",
    "                weather.set_value(i, 'rain_flag', 1)\n",
    "            elif _ == 'SN':\n",
    "                weather.set_value(i, 'snow_flag', 1)\n",
    "            elif _ == \"\":\n",
    "                weather.set_value(i, 'normal_flag', 1)\n",
    "            else:\n",
    "                weather.set_value(i, 'abnormal_flag', 1)\n",
    "\n",
    "    # return x or y depending on the condition\n",
    "    # \"For the purposes of this competition, we have defined a weather event as any day in which more than an inch of rain or two inches of snow was observed.\"\n",
    "    # weather_event =  (((codesum contains SN) and (snowfall > 2)) or ((codesum contains RA) and (preciptotal > 1)))\n",
    "    weather['preciptotal'] = TM_transform(weather['preciptotal'], 0.005, 0.00)\n",
    "    weather['snowfall'] = TM_transform(weather['snowfall'], 0.005, 0.00)\n",
    "    weather['snow_event'] = np.where(np.where(weather['snow_flag'] == 1, 1, 0) + np.where(weather['snowfall'] > 2, 1, 0) == 2, 1, 0)\n",
    "    weather['rain_event'] = np.where(np.where(weather['rain_flag'] == 1, 1, 0) + np.where(weather['preciptotal'] > 1, 1, 0) == 2, 1, 0)\n",
    "    weather['event'] = weather['snow_event'] + weather['rain_event']\n",
    "    \n",
    "    for num in range(len(weather)) :\n",
    "        if weather.at[num, 'event'] == 2 :\n",
    "            weather.set_value(num, 'event', 1)\n",
    "    \n",
    "\n",
    "#    weather['preciptotal_flag'] = np.where(weather['preciptotal'] > 0.2, 1, 0)\n",
    "#     weather['depart'] = TM_transform(weather['depart'], np.nan, 0.00)\n",
    "#     weather['depart_flag'] = np.where(weather['depart'] > 8.0, 1, 0)\n",
    "#     weather['depart_flag'] = np.where(weather['depart'] < 8.0, -1, 0)\n",
    "    \n",
    "    df = pd.merge(df, key, on='store_nbr') #key는 글로벌 변수\n",
    "    \n",
    "    df = pd.merge(df, weather[['date', 'station_nbr', 'rain_flag', 'snow_flag', 'normal_flag', 'event']], on=['date', 'station_nbr'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_preprocessing(df, holiday, weather):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "    df['weekend'] = df.date.dt.weekday.isin([5, 6])  # 5: 토요일, 6: 일요일\n",
    "\n",
    "    df['holiday'] = df.date.isin(holiday[0])\n",
    "    df['weekday_holiday'] = df.holiday & (df.weekend == False)\n",
    "    df['weekend_holiday'] = df.holiday & df.weekend\n",
    "    \n",
    "    df = pd.merge(df, key, on='store_nbr') #key는 글로벌 변수\n",
    "    df = pd.merge(df, weather[['date', 'station_nbr', 'event']], on=['date', 'station_nbr'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday12 = find_holiday('../data/holiday.xlsx', '2012')\n",
    "holiday13 = find_holiday('../data/holiday.xlsx', '2013')\n",
    "holiday14 = find_holiday('../data/holiday.xlsx', '2014')\n",
    "holiday = merge_holiday(holiday12, holiday13, holiday14)\n",
    "processed_train = preprocessing(train, holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_train.drop(['weekend', 'weekday_holiday', 'weekend_holiday', 'station_nbr',\n",
    "                      'rain_flag', 'snow_flag', 'normal_flag'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_train.sort_values(by = ['date', 'store_nbr', 'item_nbr'], inplace = True)\n",
    "processed_train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_train = processed_train[:2255853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>log_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4617595</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617596</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617597</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617598</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617599</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  units  log_units\n",
       "4617595  2014-10-31         45       107      0        0.0\n",
       "4617596  2014-10-31         45       108      0        0.0\n",
       "4617597  2014-10-31         45       109      0        0.0\n",
       "4617598  2014-10-31         45       110      0        0.0\n",
       "4617599  2014-10-31         45       111      0        0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['log_units'] = np.log(train['units'] + 1)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>log_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store_nbr  item_nbr  units  log_units\n",
       "0  2012-01-01          1         1      0        0.0\n",
       "1  2012-01-01          1         2      0        0.0\n",
       "2  2012-01-01          1         3      0        0.0\n",
       "3  2012-01-01          1         4      0        0.0\n",
       "4  2012-01-01          1         5      0        0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = train[:2255853]\n",
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = train_new.pivot_table(values = 'log_units', index = 'date', columns = ['item_nbr'])\n",
    "item_nbr_total = list(tmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = tmp.loc[:, (tmp != 0).any(axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_ = tmp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_nonzero = list(tmp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_zero = []\n",
    "\n",
    "for num in item_nbr_total :\n",
    "    if num not in item_nbr_nonzero :\n",
    "        item_nbr_zero.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num in item_nbr_zero :\n",
    "    train_new_ = train_new[train_new.item_nbr != num[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new_.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test = preprocessing(train_new_, holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test\n",
    "train_test_ = train_test.drop(['weekend', 'weekday_holiday', 'weekend_holiday', 'station_nbr',\n",
    "                               'rain_flag', 'snow_flag', 'normal_flag', 'units', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_['store_nbr'] = train_test_['store_nbr'].astype('category')\n",
    "train_test_['item_nbr'] = train_test_['item_nbr'].astype('category')\n",
    "train_test_['weekday'] = train_test_['weekday'].astype('category')\n",
    "train_test_['holiday'] = train_test_['holiday'].astype('category')\n",
    "train_test_['event'] = train_test_['event'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = sm.OLS.from_formula(\"log_units ~ store_nbr + item_nbr + weekday + holiday + event\", data = train_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = model1.fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = sm.OLS.from_formula(\"log_units ~ store_nbr + item_nbr + weekday + holiday + event + 0\", data = train_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result2 = model2.fit()\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = sm.OLS.from_formula(\"log_units ~ C(store_nbr) + C(item_nbr) + C(weekday) + C(holiday) + C(event)\", data = train_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result3 = model3.fit()\n",
    "print(result3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = sm.OLS.from_formula(\"log_units ~ C(store_nbr) + C(item_nbr) + C(weekday) + C(holiday) + C(event) + 0 + 0 + 0 + 0 + 0\", data = train_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result4 = model4.fit()\n",
    "print(result4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5 = sm.OLS.from_formula(\"log_units ~ C(item_nbr) + 0\", data = train_test_)\n",
    "result5 = model5.fit()\n",
    "print(result5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2 = train_new.pivot_table(values = 'log_units', index = ['date', 'store_nbr', 'item_nbr'])\n",
    "# tmp2_ = tmp2[tmp2['log_units'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp2_ = tmp2_.reset_index()\n",
    "tmp2 = tmp2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp2_ = preprocessing(tmp2_, holiday)\n",
    "tmp2 = preprocessing(tmp2, holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_ = preprocessing3(tmp2_, holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_test = tmp2.drop(['weekend', 'weekday_holiday', 'weekend_holiday',\n",
    "                               'rain_flag', 'snow_flag', 'normal_flag', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_test = tmp2_.drop(['weekend', 'weekday_holiday', 'weekend_holiday', 'station_nbr',\n",
    "                               'rain_flag', 'snow_flag', 'normal_flag', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_test['store_nbr'] = tmp2_test['store_nbr'].astype('category')\n",
    "tmp2_test['item_nbr'] = tmp2_test['item_nbr'].astype('category')\n",
    "tmp2_test['weekday'] = tmp2_test['weekday'].astype('category')\n",
    "tmp2_test['holiday'] = tmp2_test['holiday'].astype('category')\n",
    "tmp2_test['event'] = tmp2_test['event'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_test_add = sm.add_constant(tmp2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_test_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num in range(len(tmp2_test)) :\n",
    "    if tmp2_test.at[num, 'event'] == 2 :\n",
    "        tmp2_test.set_value(num, 'event', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS.from_formula(\"log_units ~ 0 + C(station_nbr) + C(item_nbr) + C(weekday) + C(holiday) + C(event)\", data = tmp2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- p>t : 이 column의 계수가 0이다 : 귀무사걸 \n",
    "- 기각하면 0이 아니다..constant가 0이 아니다..\n",
    "- skew,kurtosis : 잔차의 skew, kurtosis\n",
    "- prob(omnibus) 귀무가설의 잔차가 normal이다..\n",
    "- jarque-bera : normality test.. 분포가 normal이 아니다...\n",
    "- condition no : 다중공성성...크면 안좋다... 기준이 약 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.params[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f3bf6e8a96da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_formula\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"log_units ~ 0 + C(station_nbr):C(item_nbr) + C(weekday) + C(holiday) + C(event)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp2_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[1;32m--> 155\u001b[1;33m                                   missing=missing)\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[1;32m---> 65\u001b[1;33m                                NA_action=na_action)\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m--> 310\u001b[1;33m                                       NA_action, return_type)\n\u001b[0m\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is missing required outcome variables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n\u001b[0;32m    168\u001b[0m                                      \u001b[0mNA_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNA_action\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                                      return_type=return_type)\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;31m# No builders, but maybe we can still get matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36mbuild_design_matrices\u001b[1;34m(design_infos, data, NA_action, return_type, dtype)\u001b[0m\n\u001b[0;32m    931\u001b[0m         results.append(_build_design_matrix(design_info,\n\u001b[0;32m    932\u001b[0m                                             \u001b[0mfactor_info_to_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                                             dtype))\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[0mmatrices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mneed_reshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36m_build_design_matrix\u001b[1;34m(design_info, factor_info_to_values, dtype)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mneed_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesign_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDesignMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m     \u001b[0mstart_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubterms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesign_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterm_codings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = sm.OLS.from_formula(\"log_units ~ 0 + C(station_nbr):C(item_nbr) + C(weekday) + C(holiday) + C(event)\", data = tmp2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              log_units   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     12.29\n",
      "Date:                Mon, 05 Mar 2018   Prob (F-statistic):           1.12e-19\n",
      "Time:                        20:40:18   Log-Likelihood:            -1.7729e+06\n",
      "No. Observations:             2255853   AIC:                         3.546e+06\n",
      "Df Residuals:                 2255843   BIC:                         3.546e+06\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "C(weekday)[0]          0.0798      0.001     83.380      0.000       0.078       0.082\n",
      "C(weekday)[1]          0.0767      0.001     81.061      0.000       0.075       0.079\n",
      "C(weekday)[2]          0.0759      0.001     80.872      0.000       0.074       0.078\n",
      "C(weekday)[3]          0.0761      0.001     81.125      0.000       0.074       0.078\n",
      "C(weekday)[4]          0.0797      0.001     85.157      0.000       0.078       0.082\n",
      "C(weekday)[5]          0.0845      0.001     89.994      0.000       0.083       0.086\n",
      "C(weekday)[6]          0.0851      0.001     90.321      0.000       0.083       0.087\n",
      "C(holiday)[T.True]    -0.0045      0.002     -2.564      0.010      -0.008      -0.001\n",
      "C(event)[T.1]          0.0043      0.003      1.721      0.085      -0.001       0.009\n",
      "C(event)[T.2]          0.0124      0.029      0.427      0.670      -0.045       0.069\n",
      "==============================================================================\n",
      "Omnibus:                  2832985.655   Durbin-Watson:                   2.043\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        286742344.736\n",
      "Skew:                           7.229   Prob(JB):                         0.00\n",
      "Kurtosis:                      56.307   Cond. No.                         31.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "result2 = model2.fit()\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[22, 38, 47, 64, 95, 104, 105, 106, 107, 108, 109, 110, 111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub = preprocessing(test, holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub = test_sub.drop(['weekend', 'weekday_holiday', 'weekend_holiday', 'station_nbr',\n",
    "                               'rain_flag', 'snow_flag', 'normal_flag', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.predict(test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrix, demo_data, ContrastMatrix, Poly\n",
    "data = demo_data(\"a\", nlevels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmatrix(\"C(a) + 0\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmatrix(\"C(a)\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test set을 만들어서 kaggle에 제출하여 결과 매니져님께..\n",
    "- 1번카테고리가 날라가면 2번으로 대체하는 방식..? 비슷한걸로 방식..\n",
    "- 평균 그래프에서 결론을 내는건 data loss가 있을 수 있어서 위험하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
