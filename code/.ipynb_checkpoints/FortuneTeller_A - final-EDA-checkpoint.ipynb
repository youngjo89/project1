{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import pylab \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.graphics import utils\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "weather = pd.read_csv('../data/weather.csv')\n",
    "key = pd.read_csv('../data/key.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TM_transform(series, T_replace, M_replace):  # Temporary solution\n",
    "    \"\"\"\n",
    "    데이터내의 T, M을 원하는 값으로 바꿔주는 함수\n",
    "    TM_transform(series, T_replace)\n",
    "    \"\"\"\n",
    "    series = series.astype(str).map(lambda s: s.strip())\n",
    "    series[series == 'T'] = T_replace\n",
    "    series[series == 'M'] = M_replace\n",
    "    return series.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_item_nbr(df) : # 모든 units이 0이 아닌 item_nbr을 구하는 함수, list형태로 return\n",
    "    tmp = df.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "    tmp = tmp.loc[:, (tmp != 0).any(axis = 0)]\n",
    "    tmp.loc['2012-12-25'] = 0 # 2012-12-25가 빠져있음 train data에서.. 그래서 log_units = 0으로 넣어줌.\n",
    "    \n",
    "    tmp.reset_index(inplace = True)\n",
    "    tmp.sort_values(by = 'date', inplace = True)\n",
    "    tmp.drop(['date'], axis = 1, inplace = True)\n",
    "    \n",
    "    result = list(tmp.columns)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_dateformat(df, year):\n",
    "    \"\"\"\n",
    "    영문 월을 숫자 월로 바꾸어주고 나중에 사용하기 쉽도록 datetime.date 형태로 바꾸어주는 함수\n",
    "    \"\"\"\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    for i in range(len(df)):\n",
    "        dates = df.loc[i][0]\n",
    "        dates = dates.split(\" \")\n",
    "        for j in range(len(months)):\n",
    "            if dates[0] == months[j]:\n",
    "                dates[0] = str(j + 1)\n",
    "                dates_df = [\"{} {} {}\".format(year, dates[0], dates[1])]\n",
    "                dates_df = pd.to_datetime(dates_df)\n",
    "                df.loc[i][0] = dates_df.date[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_holiday(holiday_df1, holiday_df2, holiday_df3):\n",
    "    \"\"\"\n",
    "    각 연도별 공휴일 리스트 합치기\n",
    "    \"\"\"\n",
    "    frame = [holiday_df1, holiday_df2, holiday_df3]\n",
    "    holiday = pd.concat(frame).reset_index(drop=True)\n",
    "    return holiday\n",
    "\n",
    "def find_holiday(file, year):\n",
    "    \"\"\"\n",
    "    수요에 영향을 미치는 주요 공휴일을 찾아내는 함수\n",
    "    \"\"\"\n",
    "    holidays = [\"New Year's Day\", \"Martin Luther King Jr. Day\", \"Valentine's Day\",  \"President's Day\", \"Easter Sunday\", \n",
    "                      \"Mother's Day\", \"Memorial Day\", \"Father's Day\", \"Independence Day\", \"Labor Day\", \"Columbus Day\",\n",
    "                      \"Halloween\", \"Veterans Day\", \"Thanksgiving Day\", \"Black Friday\", \"Christmas Eve\", \"Christmas Day\", \"New Year's Eve\"]\n",
    "    \n",
    "    holi = pd.read_excel(file, year, header=None)\n",
    "    holi = match_dateformat(holi, year)\n",
    "    holiday = pd.DataFrame(columns=[0,1,2,3,4])\n",
    "    for _ in holidays:\n",
    "        for i in range(len(holi[2])):\n",
    "            if _ == holi[2][i]:\n",
    "                holiday = holiday.append(holi.loc[i])\n",
    "    return holiday\n",
    "\n",
    "def cs_preprocessing(codesum):\n",
    "    codesum_temp = []\n",
    "    for _ in codesum:\n",
    "        _ = _.replace('+', '')\n",
    "        _ = _.replace('-', '')\n",
    "        if len(_) > 2:\n",
    "            _1 = _[:2]\n",
    "            codesum_temp.append(_1)\n",
    "            _2 = _[2:]\n",
    "            codesum_temp.append(_2)\n",
    "        else:\n",
    "            codesum_temp.append(_)\n",
    "    codesum = codesum_temp\n",
    "    return codesum\n",
    "\n",
    "def weather_flagger(weather):\n",
    "    codesum_ls = ['FC', 'TS', 'GR', 'RA', 'DZ', 'SN', 'SG', 'GS', 'PL', 'IC', 'FG', 'BR', 'UP', 'HZ', 'FU', 'VA', 'DU', 'DS', 'PO', 'SA', 'SS', 'PY', 'SQ', 'DR', 'SH', 'FZ', 'MI', 'PR', 'BC', 'BL', 'VC']\n",
    "    weather['date'] = pd.to_datetime(weather['date']) #weather는 글로벌변수\n",
    "    for i in range(len(weather['codesum'])):\n",
    "        codesum = weather['codesum'][i].split(\" \")\n",
    "        codesum = cs_preprocessing(codesum)\n",
    "        for _ in codesum:\n",
    "            flag = any(code in _ for code in codesum_ls)\n",
    "            if flag == True:\n",
    "                weather.set_value(i, '{}_flag'.format(_), 1)\n",
    "            else:\n",
    "                weather.set_value(i, 'normal_flag', 1)\n",
    "    weather['snowfall'] = TM_transform(weather['snowfall'], 0.02, 0.0)\n",
    "    weather['preciptotal'] = TM_transform(weather['preciptotal'], 0.02, 0.0)\n",
    "    weather['snow_event'] = np.where(np.where(weather['SN_flag'] == 1, 1, 0) + np.where(weather['snowfall'] > 2, 1, 0) == 2, 1, 0)\n",
    "    weather['rain_event'] = np.where(np.where(weather['RA_flag'] == 1, 1, 0) + np.where(weather['preciptotal'] > 1, 1, 0) == 2, 1, 0)\n",
    "    weather['event'] = weather['snow_event'] + weather['rain_event']\n",
    "    weather['event'] = np.where(weather['event'] >= 1, 1, 0)\n",
    "    return weather\n",
    "\n",
    "def preprocessing(df, holiday, weather):\n",
    "    \"\"\"\n",
    "    train데이터를 가공하는 함수\n",
    "    \"\"\"\n",
    "    df['log_units'] = np.log(df['units'] + 1) # logged units\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "    df['weekend'] = df.date.dt.weekday.isin([5, 6])  # 5: 토요일, 6: 일요일\n",
    "\n",
    "    df['holiday'] = df.date.isin(holiday[0])\n",
    "    df['weekday_holiday'] = df.holiday & (df.weekend == False)\n",
    "    df['weekend_holiday'] = df.holiday & df.weekend\n",
    "    \n",
    "    df = pd.merge(df, key, on='store_nbr') #key는 글로벌 변수\n",
    "    df = pd.merge(df, weather[['date', 'station_nbr', 'tmax', 'tmin', 'tavg', 'depart', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "                               'sunrise', 'sunset', 'codesum', 'snowfall', 'preciptotal', 'stnpressure', 'sealevel', 'resultspeed',\n",
    "                               'resultspeed', 'resultdir', 'avgspeed' ,'event']], on=['date', 'station_nbr'])\n",
    "    return df\n",
    "\n",
    "def test_preprocessing(df, holiday, weather):\n",
    "    weather = weather_flagger(weather)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "    df['weekend'] = df.date.dt.weekday.isin([5, 6])  # 5: 토요일, 6: 일요일\n",
    "\n",
    "    df['holiday'] = df.date.isin(holiday[0])\n",
    "    df['weekday_holiday'] = df.holiday & (df.weekend == False)\n",
    "    df['weekend_holiday'] = df.holiday & df.weekend\n",
    "    \n",
    "    df = pd.merge(df, key, on='store_nbr') #key는 글로벌 변수\n",
    "    df = pd.merge(df, weather[['date', 'station_nbr', 'tmax', 'tmin', 'tavg', 'depart', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "                               'sunrise', 'sunset', 'codesum', 'snowfall', 'preciptotal', 'stnpressure', 'sealevel', 'resultspeed',\n",
    "                               'resultspeed', 'resultdir', 'avgspeed' ,'event']], on=['date', 'station_nbr'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def by_store(df, nbr) :\n",
    "    df_new = df[df['store_nbr'] == nbr]\n",
    "    df_new.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train[train['date'] <= '2013-03-31'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df = weather[weather['date'] <= '2013-03-31'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday12 = find_holiday('../data/holiday.xlsx', '2012')\n",
    "holiday13 = find_holiday('../data/holiday.xlsx', '2013')\n",
    "holiday14 = find_holiday('../data/holiday.xlsx', '2014')\n",
    "holiday = merge_holiday(holiday12, holiday13, holiday14)\n",
    "weather_df = weather_flagger(weather_df)\n",
    "processed_train = preprocessing(train, holiday, weather_df)\n",
    "processed_test = test_preprocessing(test, holiday, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분포 알아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS의 기본 가정인 종속 변수 y가 독립변수 x의 선형 조합으로 결정되는 기댓값과 고정된 분산 $\\sigma^{2}$를 가지는 정규 분포인지 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_norm_test = train_df.pivot_table(values='units', index=['store_nbr', 'date'], columns=['item_nbr'])\n",
    "train_df['log_units'] = np.log(train_df['units'] + 1)\n",
    "train_norm_test_log = train_df.pivot_table(values='log_units', index=['store_nbr', 'date'], columns=['item_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's draw per item_nbr per store_nbr * with units\n",
    "for i in range(1,2):  #원래는 1~45\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    t = []\n",
    "    temp = train_norm_test.loc[i]\n",
    "    temp2 = train_norm_test_log.loc[i]\n",
    "    temp = temp.loc[:, (temp !=0).any(axis=0)]\n",
    "    temp2 = temp2.loc[:, (temp2 !=0).any(axis=0)]\n",
    "    t = list(temp.columns)\n",
    "    for j in t:\n",
    "        plt.figure(figsize = (30, 20))\n",
    "        plt.subplot(4,2,1)\n",
    "        sns.distplot(temp[j], kde=True, fit=scipy.stats.norm)\n",
    "        plt.title('Units')\n",
    "        plt.subplot(4,2,2)\n",
    "        sns.distplot(temp2[j], kde=True, fit=scipy.stats.norm)\n",
    "        plt.title('Log_unit')\n",
    "        plt.subplot(4,2,3)\n",
    "        scipy.stats.probplot(temp[j], dist=\"norm\", plot=pylab)\n",
    "        plt.subplot(4,2,4)\n",
    "        scipy.stats.probplot(temp2[j], dist=\"norm\", plot=pylab)\n",
    "        pylab.show()\n",
    "        result_ks = scipy.stats.kstest(temp[j], cdf='norm')\n",
    "        result_ks_log = scipy.stats.kstest(temp2[j], cdf='norm')\n",
    "        print('Unit - test statistic: {}, p-value: {}'.format(result_ks[0], result_ks[1]))\n",
    "        print('Log Unit - test statistic: {}, p-value: {}'.format(result_ks_log[0], result_ks_log[1]))\n",
    "        print(\"Unit - Skewness: %f\" % temp[j].skew())\n",
    "        print(\"Unit - Kurtosis: %f\" % temp[j].kurt())\n",
    "        print(\"Log Unit - Skewness: %f\" % temp2[j].skew())\n",
    "        print(\"Log Unit - Kurtosis: %f\" % temp2[j].kurt())\n",
    "    # It seems like improving the normality!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로그를 취하지 않은 종속변수 y값은 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로그를 취한 유닛으로 시간별 판매량을 플롯함으로써 추세, 계절성이 있는지 알아보자\n",
    "\n",
    "여기에서 UCL은 평균값에 2 Sigma를 더한값이라 하고, 범위안에 속하지 못하는 데이터는 odd하다고 가정한다. (95.45%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 2): #원래는 1~45\n",
    "    tmp = []\n",
    "    tmp = train_df[train_df['store_nbr'] == i]\n",
    "    tmp_sold = tmp[tmp['units'] > 0]\n",
    "    tmp = pd.concat([tmp[tmp['item_nbr'] == num] for num in tmp_sold['item_nbr'].unique()])\n",
    "    for j in tmp['item_nbr'].unique():\n",
    "        tmp_item = []\n",
    "        tmp_item = tmp[tmp['item_nbr'] == j]\n",
    "        tmp_item['index'] = [k for k in range(len(tmp_item))]\n",
    "        mean = tmp_item['log_units'].mean()\n",
    "        std = tmp_item['log_units'].std()\n",
    "        sig = np.sqrt(std)\n",
    "        UCL = (sig*2) + mean # 2sigma 95.45%\n",
    "        tmp_item['UCL'] = UCL\n",
    "        tmp_item_odd = tmp_item[tmp_item['log_units'] > UCL]\n",
    "        ax = tmp_item.plot(x='date', y='log_units', kind='line', figsize=(20,2), title=('{} Store, {} Item'.format(i, j)))\n",
    "        tmp_item.plot(x='date', y='UCL', kind='line', style=':', ax=ax)\n",
    "        if len(tmp_item_odd) != 0:\n",
    "            tmp_item_odd.plot(x='index', y='log_units', kind='scatter', color='r', ax=ax)\n",
    "#          plt.title('{} Store, {} Item'.format(i, j))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 oddity는 어디서 나온 것일까? 요일별로 판매량이 다른지 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_train_f1 = processed_train.pivot_table(values='units', index=['weekday'], aggfunc=np.sum)\n",
    "processed_train_f2 = processed_train[processed_train['units'] > 0].reset_index(drop=True)\n",
    "processed_train_f3 = processed_train[processed_train['log_units'] > 0].reset_index(drop=True)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize = (25, 7))\n",
    "# unit vs weekday\n",
    "processed_train_f1.plot(kind='line', style='r', ax=axes[0])\n",
    "# axes[1].set_ylim([0,200])\n",
    "plt.xticks(rotation=0)\n",
    "axes[0].set_ylabel('Total Units')\n",
    "axes[0].set_xlabel('Weekday')\n",
    "processed_train_f2.boxplot(\"units\", \"weekday\", ax=axes[1])\n",
    "axes[1].set_ylim([0,200])\n",
    "plt.xticks(rotation=0)\n",
    "axes[1].set_ylabel('Units')\n",
    "axes[1].set_xlabel('Weekday')\n",
    "processed_train_f3.boxplot(\"log_units\", \"weekday\", ax=axes[2])\n",
    "axes[2].set_ylim([0,7.5])\n",
    "plt.xticks(rotation=0)\n",
    "axes[2].set_ylabel('Units')\n",
    "axes[2].set_xlabel('Weekday')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유닛의 총량으로 보았을때는 차이가 분명히 나타나지만 boxplot으로 보았을때 커다란 차이점을 보기는 힘들다. (특히 유닛에 로그를 취했을 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_train = preprocessing(train_df, holiday, weather_df)\n",
    "processed_train['date'] = processed_train['date'].apply(lambda x:x.date().strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 2):  #원래는 1~45\n",
    "    tmp = []\n",
    "    tmp_sold = []\n",
    "    tmp = processed_train[processed_train['store_nbr'] == i]\n",
    "    tmp_sold = tmp[tmp['log_units'] > 0]\n",
    "    tmp = pd.concat([tmp[tmp['item_nbr'] == num] for num in tmp_sold['item_nbr'].unique()])\n",
    "    for j in tmp['item_nbr'].unique():\n",
    "        tmp_item = []\n",
    "        tmp_item_odd = []\n",
    "        tmp_item_mon = []\n",
    "        tmp_item_tue = []\n",
    "        tmp_item_wed = []\n",
    "        tmp_item_thu = []\n",
    "        tmp_item_fri = []\n",
    "        tmp_item_sat = []\n",
    "        tmp_item_sun = []\n",
    "        tmp_item = tmp[tmp['item_nbr'] == j]\n",
    "        tmp_item['index'] = [k for k in range(len(tmp_item))]\n",
    "        mean = tmp_item['log_units'].mean()\n",
    "        std = tmp_item['log_units'].std()\n",
    "        sig = np.sqrt(std)\n",
    "        UCL = (sig*2) + mean # 2sigma 95.45%\n",
    "        tmp_item['UCL'] = UCL\n",
    "        tmp_item_odd = tmp_item[tmp_item['log_units'] > UCL]\n",
    "        tmp_item_mon = tmp_item_odd[tmp_item_odd['weekday'] == 0]\n",
    "        tmp_item_tue = tmp_item_odd[tmp_item_odd['weekday'] == 1]\n",
    "        tmp_item_wed = tmp_item_odd[tmp_item_odd['weekday'] == 2]\n",
    "        tmp_item_thu = tmp_item_odd[tmp_item_odd['weekday'] == 3]\n",
    "        tmp_item_fri = tmp_item_odd[tmp_item_odd['weekday'] == 4]\n",
    "        tmp_item_sat = tmp_item_odd[tmp_item_odd['weekday'] == 5]\n",
    "        tmp_item_sun = tmp_item_odd[tmp_item_odd['weekday'] == 6]\n",
    "        ax = tmp_item.plot(x='date', y='log_units', kind='line', figsize=(20,4), title=('{} Store, {} Item'.format(i, j)))\n",
    "        tmp_item.plot(x='date', y='UCL', kind='line', style=':', ax=ax)\n",
    "        if len(tmp_item_odd) != 0:\n",
    "            tmp_item_odd.plot(x='index', y='log_units', kind='scatter', color='r', alpha='0.0', ax=ax)\n",
    "            if len(tmp_item_mon) != 0:\n",
    "                tmp_item_mon.plot(x='index', y='log_units', kind='scatter', color='#FFA500', ax=ax) # orange\n",
    "                print('Monday: {}'.format(len(tmp_item_mon)))\n",
    "\n",
    "            if len(tmp_item_tue) != 0:\n",
    "                tmp_item_tue.plot(x='index', y='log_units', kind='scatter', color='#FF69B4', ax=ax) # pink\n",
    "                print('Tuesday: {}'.format(len(tmp_item_tue)))\n",
    "\n",
    "            if len(tmp_item_wed) !=0:\n",
    "                tmp_item_wed.plot(x='index', y='log_units', kind='scatter', color='y', ax=ax)\n",
    "                print('Wednsday: {}'.format(len(tmp_item_wed)))\n",
    "\n",
    "            if len(tmp_item_thu) != 0:\n",
    "                tmp_item_thu.plot(x='index', y='log_units', kind='scatter', color='g', ax=ax)\n",
    "                print('Thurday: {}'.format(len(tmp_item_thu)))\n",
    "\n",
    "            if len(tmp_item_fri) != 0:\n",
    "                tmp_item_fri.plot(x='index', y='log_units', kind='scatter', color='b', ax=ax)\n",
    "                print('Friday: {}'.format(len(tmp_item_fri)))\n",
    "\n",
    "            if len(tmp_item_sat) != 0:\n",
    "                tmp_item_sat.plot(x='index', y='log_units', kind='scatter', color='#00008B', ax=ax) # darkblue\n",
    "                print('Satday: {}'.format(len(tmp_item_sat)))\n",
    "\n",
    "            if len(tmp_item_sun) != 0:    \n",
    "                tmp_item_sun.plot(x='index', y='log_units', kind='scatter', color='m', ax=ax)            \n",
    "                print('Sunday: {}'.format(len(tmp_item_sun)))\n",
    "                           \n",
    "            plt.show()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공휴일이 미치는 영향도 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_holiday = train_df[train_df['holiday'] == True].reset_index(drop = True)\n",
    "train_df_nonholiday = train_df[train_df['holiday'] == False].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 2) : # 1 ~ 45\n",
    "    plt.subplots(figsize = (23, 400))\n",
    "    plt.subplot(90, 1, i)\n",
    "    sns.boxplot(x = 'item_nbr', y = 'log_units', data = by_store(train_df_holiday, i))\n",
    "        \n",
    "    plt.title('store_nbr = {}'.format(i))\n",
    "    \n",
    "    plt.subplot(90, 1, i + 1)\n",
    "    sns.boxplot(x = 'item_nbr', y = 'log_units', data = by_store(train_df_nonholiday, i))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_train_f4 = processed_train[processed_train['units'] > 0]\n",
    "processed_train_f5 = processed_train[processed_train['log_units'] > 0]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (10, 7))\n",
    "processed_train_f4.boxplot(\"units\", \"holiday\", ax=axes[0])\n",
    "axes[0].set_ylim([0,150])\n",
    "processed_train_f5.boxplot(\"log_units\", \"holiday\", ax=axes[1])\n",
    "axes[1].set_ylim([0,7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 이 odd한 날이 weather의 영향을 받은 날일까? \n",
    "\n",
    "문제에서 preciptotal이 1이상 snowfall이 2이상인날을 weather event, 즉 stormy weather한 날이라고 정의하였다. \n",
    "\n",
    "이 날짜에 맞춰 event가 발생하였다고 가정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_pivot_station_train = processed_train.pivot_table(values='event', index='date', columns='station_nbr')\n",
    "event_pivot_station_test = processed_test.pivot_table(values='event', index='date', columns='station_nbr')\n",
    "event_pivot_store_train = processed_train.pivot_table(values='event', index='date', columns='store_nbr')\n",
    "event_pivot_store_test = processed_test.pivot_table(values='event', index='date', columns='store_nbr')\n",
    "event_pivot_station_train = pd.DataFrame(event_pivot_station_train.to_records())\n",
    "event_pivot_station_test = pd.DataFrame(event_pivot_station_test.to_records())\n",
    "event_pivot_store_train = pd.DataFrame(event_pivot_store_train.to_records())\n",
    "event_pivot_store_test = pd.DataFrame(event_pivot_store_test.to_records())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 플롯한 추세, 계절성 플롯에서 odd한 값들이 event에 영향을 받은것인지 알아보기 위해 같은 플롯을 그려보자\n",
    "\n",
    "event는 초록색 odd는 빨간색 둘이 겹치는 부분은 두색의 합으로 나타난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 3): #원래는 1~45\n",
    "    tmp = []\n",
    "    tmp_item_flag = []\n",
    "    tmp = processed_train[processed_train['store_nbr'] == i]\n",
    "    tmp_sold = tmp[tmp['log_units'] > 0]\n",
    "    tmp = pd.concat([tmp[tmp['item_nbr'] == num] for num in tmp_sold['item_nbr'].unique()])\n",
    "    for j in tmp['item_nbr'].unique():\n",
    "        tmp_item = tmp[tmp['item_nbr'] == j]\n",
    "        tmp_item['index'] = [k for k in range(len(tmp_item))]\n",
    "        mean = tmp_item['log_units'].mean()\n",
    "        std = tmp_item['log_units'].std()\n",
    "        sig = np.sqrt(std)\n",
    "        UCL = (sig*2) + mean # 2sigma 95.45%\n",
    "        tmp_item['UCL'] = UCL\n",
    "        tmp_item_odd = tmp_item[tmp_item['log_units'] > UCL]\n",
    "        tmp_item_event = tmp_item[tmp_item['event'] > 0]\n",
    "        tmp_item_flag = tmp_item_event[tmp_item_event['log_units'] > UCL]\n",
    "        ax = tmp_item.plot(x='date', y='log_units', kind='line', figsize=(20,4), title=('{} Store, {} Item'.format(i, j)))\n",
    "        tmp_item.plot(x='date', y='UCL', kind='line', style=':', ax=ax)\n",
    "        if len(tmp_item_odd) != 0:\n",
    "            tmp_item_event.plot(x='index', y='log_units', kind='scatter', color='g', ax=ax)\n",
    "            tmp_item_odd.plot(x='index', y='log_units', kind='scatter', color='r', ax=ax)\n",
    "            if len(tmp_item_flag) !=0:\n",
    "                tmp_item_flag.plot(x='index', y='log_units', kind='scatter', color='c', ax=ax)\n",
    "                print('Warning! : {}, Match: {}'.format(tmp_item_flag['date'], len(tmp_item_flag)))\n",
    "        else:\n",
    "            tmp_item_event.plot(x='index', y='log_units', kind='scatter', color='g', ax=ax)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "event와 odd가 겹쳐질때 warning을 주도록 하였는데 겹치는 경우가 희소하다. \n",
    "\n",
    "그렇다면 다른 weather정보가 unit에 영향을 미치는지 알아보도록 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_tmp = weather[weather['date'] <= '2013-03-31'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_col_ls = list(weather_tmp.columns)\n",
    "for col in w_col_ls:\n",
    "    if col == 'date':\n",
    "        weather_tmp[col] = weather_tmp[col]\n",
    "    elif col == 'sunrise':\n",
    "        weather_tmp[col] = weather_tmp[col]\n",
    "    elif col == 'sunset':\n",
    "        weather_tmp[col] = weather_tmp[col]\n",
    "    elif col == 'codesum':\n",
    "        weather_tmp[col] = weather_tmp[col]\n",
    "    else:\n",
    "        weather_tmp[col] = TM_transform(weather_tmp[col], 0.001, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_tmp = weather_tmp.replace('M', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_tmp.drop(['RA_flag', 'FZ_flag', 'FG_flag', 'BR_flag', 'normal_flag',\n",
    "       'UP_flag', 'MI_flag', 'SN_flag', 'HZ_flag', 'TS_flag', 'VC_flag',\n",
    "       'DZ_flag', 'BL_flag', 'BC_flag', 'DU_flag', 'SQ_flag', 'PL_flag',\n",
    "       'FU_flag', 'GR_flag', 'GS_flag', 'SG_flag', 'PR_flag', 'snow_event',\n",
    "       'rain_event'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weather_tmp['date'] = weather_tmp['date'].apply(lambda x:x.date().strftime('%Y-%m-%d'))\n",
    "# weather_tmp = weather_tmp.dropna(how='any', axis=0)\n",
    "# weather_tmp = weather_tmp.astype('float')\n",
    "weather_tmp = weather_tmp.reset_index(drop=True)\n",
    "weather_tmp['station_nbr'] = weather_tmp['station_nbr'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for station_nbr in range(1, 2) : # 1~20번 station\n",
    "    weather_tmp_st = weather_tmp[weather_tmp['station_nbr'] == station_nbr].reset_index(drop = True)\n",
    "    train_df_ = pd.merge(train_df, key, on = 'store_nbr')\n",
    "    train_df_st = train_df_[train_df_['station_nbr'] == station_nbr]\n",
    "    \n",
    "    nonzero = train_df_st[train_df_st['log_units'] > 0]\n",
    "    item_nbr_list = list(nonzero['item_nbr'].unique())\n",
    "    \n",
    "    for item_nbr in item_nbr_list :\n",
    "        train_df_st_it = train_df_st[train_df_st['item_nbr'] == item_nbr]\n",
    "        weather_tmp_st_it = pd.merge(weather_tmp_st, train_df_st_it, on = ['date', 'station_nbr'])\n",
    "        \n",
    "        sns.pairplot(weather_tmp_st_it, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb'],\n",
    "                     y_vars=['units', 'log_units'], kind='reg')\n",
    "        plt.show()\n",
    "\n",
    "        sns.pairplot(weather_tmp_st_it, x_vars=['heat', 'cool', 'preciptotal', 'stnpressure', 'resultspeed'],\n",
    "                     y_vars=['units', 'log_units'], kind='reg')\n",
    "        plt.show()\n",
    "\n",
    "        sns.pairplot(weather_tmp_st_it, x_vars=['avgspeed', 'weekday', 'weekend', 'holiday', 'weekday_holiday', 'weekend_holiday'],\n",
    "                     y_vars=['units', 'log_units'], kind='reg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weather column간 관계\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['tmax'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['tmin'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['tavg'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['dewpoint'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['wetbulb'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['heat'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['cool'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['preciptotal'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['stnpressure'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['resultspeed'], kind='reg')\n",
    "plt.show()\n",
    "sns.pairplot(weather_tmp, x_vars=['tmax', 'tmin', 'tavg', 'dewpoint', 'wetbulb', 'heat', 'cool',\n",
    "       'preciptotal', 'stnpressure', 'resultspeed', 'avgspeed'], y_vars=['avgspeed'], kind='reg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temperature와 dewpoint wetbulb, cool과 heat외에는 상관관계가 없어보인다. 상관계수를 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['log_units'] = np.log(train_df['units'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.merge(train_df, key, on = 'store_nbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = tmp[tmp['units'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 weather station별로 units이 0이 아닌 item_nbr들의 units와 weather column들 간의 correlation을 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weather_tmp.drop(['RA_flag', 'FZ_flag', 'FG_flag', 'BR_flag', 'normal_flag',\n",
    "#        'UP_flag', 'MI_flag', 'SN_flag', 'HZ_flag', 'TS_flag', 'VC_flag',\n",
    "#        'DZ_flag', 'BL_flag', 'BC_flag', 'DU_flag', 'SQ_flag', 'PL_flag',\n",
    "#        'FU_flag', 'GR_flag', 'GS_flag', 'SG_flag', 'PR_flag', 'snow_event',\n",
    "#        'rain_event'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in range(1, 2) : #station_nbr은 1~20까지....\n",
    "    weather_cor = weather_tmp[weather_tmp['station_nbr'] == x]\n",
    "    tmp_ = tmp[tmp['station_nbr'] == x]\n",
    "    weather_cor1 = pd.merge(weather_cor, tmp_, on = 'station_nbr')\n",
    "    item_nbr_list = list(weather_cor1['item_nbr'].unique())\n",
    "\n",
    "    for num in item_nbr_list :\n",
    "        weather_cor_ = weather_cor1[weather_cor1['item_nbr'] == num]\n",
    "        plt.figure(figsize=(20,15))\n",
    "        sns.heatmap(weather_cor_.corr(), annot = True, fmt = '.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 관심있는 units와 log_units는 weather와는 별로 연관성이 없어보인다. 어떻게 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 보았다시피 각 스토어, 각 아이템별로 나누어 모델링을 해야함은 분명하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weather와 log_units(또는 units)의 큰 상관관계는 없는 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그나마 weekday와 holiday가 log_units(또는 units)에 영향을 미치는 것으로 보인다(item_nbr에 따라 다름)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
