{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('../data/key.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "weather = pd.read_csv('../data/weather.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>log_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4617595</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617596</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617597</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617598</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617599</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  units  log_units\n",
       "4617595  2014-10-31         45       107      0        0.0\n",
       "4617596  2014-10-31         45       108      0        0.0\n",
       "4617597  2014-10-31         45       109      0        0.0\n",
       "4617598  2014-10-31         45       110      0        0.0\n",
       "4617599  2014-10-31         45       111      0        0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['log_units'] = np.log(train['units'] + 1)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = train[train['date'] <= '2013-03-31']\n",
    "train_new.reset_index(drop = True, inplace = True) # 2013년 3월 31일까지의 train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def M_transform(df, column): #moving average (recursive)\n",
    "    tmp_sorted = df.sort_values(by=['station_nbr','date']).reset_index(drop=True)\n",
    "    weather_new = pd.DataFrame(columns=['station_nbr', 'date', 'tmax', 'tmin', 'tavg', 'depart', 'dewpoint',\n",
    "           'wetbulb', 'heat', 'cool', 'sunrise', 'sunset', 'codesum', 'snowfall',\n",
    "           'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
    "           'avgspeed'])\n",
    "    window = 2\n",
    "    for j in range(1, 21):\n",
    "        tmp_station = []\n",
    "        tmp_station = tmp_sorted[tmp_sorted['station_nbr'] == j].reset_index(drop=True)\n",
    "        if j == 5:\n",
    "            weather_new = pd.concat([weather_new, tmp_station])\n",
    "        else:\n",
    "            for i in range(len(tmp_station)):\n",
    "                if tmp_station[column].at[i] == 'M':\n",
    "                    tmp = 0.0\n",
    "                    if i == 0:\n",
    "                        result = 0.0\n",
    "                    else:\n",
    "                        for x in range(1, window + 1):\n",
    "                            tmp += float(tmp_station[column].at[i - x])\n",
    "                            result = float(round(tmp / window, 2))\n",
    "                            tmp_station[column].set_value(i, result)\n",
    "            weather_new = pd.concat([weather_new, tmp_station]).reset_index(drop=True)\n",
    "    return weather_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TM_transform(series, T_replace, M_replace):  # Temporary solution\n",
    "    \"\"\"\n",
    "    데이터내의 T, M을 원하는 값으로 바꿔주는 함수\n",
    "    TM_transform(series, T_replace)\n",
    "    \"\"\"\n",
    "    series = series.astype(str).map(lambda s: s.strip())\n",
    "    series[series == 'T'] = T_replace\n",
    "    series[series == 'M'] = M_replace\n",
    "    return series.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def T_transform(series, T_replace): \n",
    "    \"\"\"\n",
    "    데이터내의 T, M을 원하는 값으로 바꿔주는 함수\n",
    "    TM_transform(series, T_replace)\n",
    "    \"\"\"\n",
    "    series = series.astype(str).map(lambda s: s.strip())\n",
    "    series[series == 'T'] = T_replace\n",
    "    series[series == 'M'] = 'M'\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weather_flagger(weather):\n",
    "    codesum_ls = ['FC', 'TS', 'GR', 'RA', 'DZ', 'SN', 'SG', 'GS', 'PL', 'IC', 'FG', 'BR', 'UP', 'HZ', 'FU', 'VA', 'DU', 'DS', 'PO', 'SA', 'SS', 'PY', 'SQ', 'DR', 'SH', 'FZ', 'MI', 'PR', 'BC', 'BL', 'VC']\n",
    "    weather['date'] = pd.to_datetime(weather['date']) #weather는 글로벌변수\n",
    "    for i in range(len(weather['codesum'])):\n",
    "        codesum = weather['codesum'][i].split(\" \")\n",
    "        codesum = cs_preprocessing(codesum)\n",
    "        for _ in codesum:\n",
    "            flag = any(code in _ for code in codesum_ls)\n",
    "            if flag == True:\n",
    "                weather.set_value(i, '{}_flag'.format(_), 1)\n",
    "            else:\n",
    "                weather.set_value(i, 'normal_flag', 1)\n",
    "\n",
    "    # return x or y depending on the condition\n",
    "    # \"For the purposes of this competition, we have defined a weather event as any day in which more than an inch of rain or two inches of snow was observed.\"\n",
    "    # weather_event =  (((codesum contains SN) and (snowfall > 2)) or ((codesum contains RA) and (preciptotal > 1)))\n",
    "    weather['preciptotal'] = T_transform(weather['preciptotal'], 0.001)\n",
    "    weather['snowfall'] = TM_transform(weather['snowfall'], 0.001, 0.0)\n",
    "    weather = M_transform(weather, \"preciptotal\")\n",
    "    weather['preciptotal'] = TM_transform(weather['preciptotal'], 0.001, 0.0)\n",
    "#     weather = M_transform(weather, \"snowfall\")\n",
    "    weather['snow_event'] = np.where(np.where(weather['SN_flag'] == 1, 1, 0) + np.where(weather['snowfall'] > 2, 1, 0) == 2, 1, 0)\n",
    "    weather['rain_event'] = np.where(np.where(weather['RA_flag'] == 1, 1, 0) + np.where(weather['preciptotal'] > 1, 1, 0) == 2, 1, 0)\n",
    "    weather['event'] = weather['snow_event'] + weather['rain_event']\n",
    "    weather['event'] = np.where(weather['event'] >= 1, 1, 0)\n",
    "    #    weather['preciptotal_flag'] = np.where(weather['preciptotal'] > 0.2, 1, 0)\n",
    "    #     weather['depart'] = TM_transform(weather['depart'], np.nan, 0.00)\n",
    "    #     weather['depart_flag'] = np.where(weather['depart'] > 8.0, 1, 0)\n",
    "    #     weather['depart_flag'] = np.where(weather['depart'] < 8.0, -1, 0)\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather 관련 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weather_train(df, station_nbr) : # staion_nbr에 따라서 weather train dataframe을 만드는 함수\n",
    "    new_df = df[df['station_nbr'] == station_nbr]\n",
    "    new_df.reset_index(drop = True, inplace = True)\n",
    "    return new_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 관련 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_train(df, store_nbr) : # store_nbr에 따라 train data를 나눠주는 함수\n",
    "    new_df = df[df['store_nbr'] == store_nbr]\n",
    "    new_df.reset_index(drop = True, inplace = True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather와 train data를 합쳐주는 함수\n",
    "- train data 중 log_units != 0 인 item들만 합쳐줌.. (log_units != 0 이면 units != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_weather_train(weather, train) :\n",
    "    train_pivot = train.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "    train_pivot = train_pivot.loc[:, (train_pivot != 0).any(axis = 0)] # log_units이 모두 0인 item_nbr(column)을 삭제..\n",
    "    train_pivot.loc['2012-12-25'] = 0 # 2012-12-25의 data를 0으로 추가... 원래 없었던 data이므로 0으로 설정함\n",
    "    \n",
    "    list_item_nbr = train_pivot.columns # units 전체가 0이 아닌 item_nbr들을 list형태로 받음\n",
    "#     length = len(train_pivot.columns) # units전체가 0이 아닌 item_nbr이 총 몇개 있는지..\n",
    "        \n",
    "    train_pivot.index.name = \"date\"\n",
    "    train_pivot.reset_index(inplace = True)\n",
    "    train_pivot.sort_values(by = 'date', inplace = True)\n",
    "    train_pivot.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    for num in list_item_nbr :\n",
    "        weather[num] = train_pivot[num]\n",
    "    \n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_item_nbr(df) : # 모든 units이 0이 아닌 item_nbr을 구하는 함수, list형태로 return\n",
    "    tmp = df.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "    tmp = tmp.loc[:, (tmp != 0).any(axis = 0)]\n",
    "    tmp.loc['2012-12-25'] = 0 # 2012-12-25가 빠져있음 train data에서.. 그래서 log_units = 0으로 넣어줌.\n",
    "    \n",
    "    tmp.reset_index(inplace = True)\n",
    "    tmp.sort_values(by = 'date', inplace = True)\n",
    "    tmp.drop(['date'], axis = 1, inplace = True)\n",
    "    \n",
    "    result = list(tmp.columns)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_dateformat(df, year):\n",
    "    \"\"\"\n",
    "    영문 월을 숫자 월로 바꾸어주고 나중에 사용하기 쉽도록 datetime.date 형태로 바꾸어주는 함수\n",
    "    \"\"\"\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    for i in range(len(df)):\n",
    "        dates = df.loc[i][0]\n",
    "        dates = dates.split(\" \")\n",
    "        for j in range(len(months)):\n",
    "            if dates[0] == months[j]:\n",
    "                dates[0] = str(j + 1)\n",
    "                dates_df = [\"{} {} {}\".format(year, dates[0], dates[1])]\n",
    "                dates_df = pd.to_datetime(dates_df)\n",
    "                df.loc[i][0] = dates_df.date[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_holiday(holiday_df1, holiday_df2, holiday_df3):\n",
    "    \"\"\"\n",
    "    각 연도별 공휴일 리스트 합치기\n",
    "    \"\"\"\n",
    "    frame = [holiday_df1, holiday_df2, holiday_df3]\n",
    "    holiday = pd.concat(frame).reset_index(drop=True)\n",
    "    return holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_holiday(file, year):\n",
    "    \"\"\"\n",
    "    수요에 영향을 미치는 주요 공휴일을 찾아내는 함수\n",
    "    \"\"\"\n",
    "    holidays = [\"New Year's Day\", \"Martin Luther King Jr. Day\", \"Valentine's Day\",  \"President's Day\", \"Easter Sunday\", \n",
    "                      \"Mother's Day\", \"Memorial Day\", \"Father's Day\", \"Independence Day\", \"Labor Day\", \"Columbus Day\",\n",
    "                      \"Halloween\", \"Veterans Day\", \"Thanksgiving Day\", \"Black Friday\", \"Christmas Eve\", \"Christmas Day\", \"New Year's Eve\"]\n",
    "    \n",
    "    holi = pd.read_excel(file, year, header=None)\n",
    "    holi = match_dateformat(holi, year)\n",
    "    holiday = pd.DataFrame(columns=[0,1,2,3,4])\n",
    "    for _ in holidays:\n",
    "        for i in range(len(holi[2])):\n",
    "            if _ == holi[2][i]:\n",
    "                holiday = holiday.append(holi.loc[i])\n",
    "    return holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cs_preprocessing(codesum):\n",
    "    codesum_temp = []\n",
    "    for _ in codesum:\n",
    "        _ = _.replace('+', '')\n",
    "        _ = _.replace('-', '')\n",
    "        if len(_) > 2:\n",
    "            _1 = _[:2]\n",
    "            codesum_temp.append(_1)\n",
    "            _2 = _[2:]\n",
    "            codesum_temp.append(_2)\n",
    "        else:\n",
    "            codesum_temp.append(_)\n",
    "    codesum = codesum_temp\n",
    "    return codesum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_preprocessing(df, holiday, weather):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "    df['weekend'] = df.date.dt.weekday.isin([5, 6])  # 5: 토요일, 6: 일요일\n",
    "\n",
    "    df['holiday'] = df.date.isin(holiday[0])\n",
    "    \n",
    "    df = pd.merge(df, key, on='store_nbr') #key는 글로벌 변수\n",
    "    df = pd.merge(df, weather[['date', 'station_nbr', 'event', 'snowfall', 'preciptotal']], on=['date', 'station_nbr'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday12 = find_holiday('../data/holiday.xlsx', '2012')\n",
    "holiday13 = find_holiday('../data/holiday.xlsx', '2013')\n",
    "holiday14 = find_holiday('../data/holiday.xlsx', '2014')\n",
    "holiday = merge_holiday(holiday12, holiday13, holiday14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather_flagger(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "weather['weekday'] = weather.date.dt.weekday  # 월요일이 0 일요일이 6\n",
    "\n",
    "weather['holiday'] = weather.date.isin(holiday[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_train = weather[weather['date'] <= '2013-03-31']\n",
    "weather_train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#station_nbr로 weather_train을 나눠줌\n",
    "# 박두진 강사님이 이 부분을 줄일 수 있는 방법을 찾아봐주신다 하였음..일단은 그냥 쓰자!\n",
    "\n",
    "weather_train_1 = get_weather_train(weather_train, 1)\n",
    "weather_train_2 = get_weather_train(weather_train, 2)\n",
    "weather_train_3 = get_weather_train(weather_train, 3)\n",
    "weather_train_4 = get_weather_train(weather_train, 4)\n",
    "weather_train_5 = get_weather_train(weather_train, 5) # missing value가 많아서 일단은..\n",
    "weather_train_6 = get_weather_train(weather_train, 6)\n",
    "weather_train_7 = get_weather_train(weather_train, 7)\n",
    "weather_train_8 = get_weather_train(weather_train, 8)\n",
    "weather_train_9 = get_weather_train(weather_train, 9)\n",
    "weather_train_10 = get_weather_train(weather_train, 10)\n",
    "weather_train_11 = get_weather_train(weather_train, 11)\n",
    "weather_train_12 = get_weather_train(weather_train, 12)\n",
    "weather_train_13 = get_weather_train(weather_train, 13)\n",
    "weather_train_14 = get_weather_train(weather_train, 14)\n",
    "weather_train_15 = get_weather_train(weather_train, 15)\n",
    "weather_train_16 = get_weather_train(weather_train, 16)\n",
    "weather_train_17 = get_weather_train(weather_train, 17)\n",
    "weather_train_18 = get_weather_train(weather_train, 18)\n",
    "weather_train_19 = get_weather_train(weather_train, 19)\n",
    "weather_train_20 = get_weather_train(weather_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new_1 = get_train_train(train_new, 1)\n",
    "train_new_2 = get_train_train(train_new, 2)\n",
    "train_new_3 = get_train_train(train_new, 3)\n",
    "train_new_4 = get_train_train(train_new, 4)\n",
    "train_new_5 = get_train_train(train_new, 5)\n",
    "train_new_6 = get_train_train(train_new, 6)\n",
    "train_new_7 = get_train_train(train_new, 7)\n",
    "train_new_8 = get_train_train(train_new, 8)\n",
    "train_new_9 = get_train_train(train_new, 9)\n",
    "train_new_10 = get_train_train(train_new, 10)\n",
    "train_new_11 = get_train_train(train_new, 11)\n",
    "train_new_12 = get_train_train(train_new, 12)\n",
    "train_new_13 = get_train_train(train_new, 13)\n",
    "train_new_14 = get_train_train(train_new, 14)\n",
    "train_new_15 = get_train_train(train_new, 15)\n",
    "train_new_16 = get_train_train(train_new, 16)\n",
    "train_new_17 = get_train_train(train_new, 17)\n",
    "train_new_18 = get_train_train(train_new, 18)\n",
    "train_new_19 = get_train_train(train_new, 19)\n",
    "train_new_20 = get_train_train(train_new, 20)\n",
    "train_new_21 = get_train_train(train_new, 21)\n",
    "train_new_22 = get_train_train(train_new, 22)\n",
    "train_new_23 = get_train_train(train_new, 23)\n",
    "train_new_24 = get_train_train(train_new, 24)\n",
    "train_new_25 = get_train_train(train_new, 25)\n",
    "train_new_26 = get_train_train(train_new, 26)\n",
    "train_new_27 = get_train_train(train_new, 27)\n",
    "train_new_28 = get_train_train(train_new, 28)\n",
    "train_new_29 = get_train_train(train_new, 29)\n",
    "train_new_30 = get_train_train(train_new, 30)\n",
    "train_new_31 = get_train_train(train_new, 31)\n",
    "train_new_32 = get_train_train(train_new, 32)\n",
    "train_new_33 = get_train_train(train_new, 33)\n",
    "train_new_34 = get_train_train(train_new, 34)\n",
    "train_new_35 = get_train_train(train_new, 35)\n",
    "train_new_36 = get_train_train(train_new, 36)\n",
    "train_new_37 = get_train_train(train_new, 37)\n",
    "train_new_38 = get_train_train(train_new, 38)\n",
    "train_new_39 = get_train_train(train_new, 39)\n",
    "train_new_40 = get_train_train(train_new, 40)\n",
    "train_new_41 = get_train_train(train_new, 41)\n",
    "train_new_42 = get_train_train(train_new, 42)\n",
    "train_new_43 = get_train_train(train_new, 43)\n",
    "train_new_44 = get_train_train(train_new, 44)\n",
    "train_new_45 = get_train_train(train_new, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['date'] = pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>526912</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>45</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526913</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526914</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526915</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526916</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>45</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store_nbr  item_nbr\n",
       "526912 2014-10-26         45       107\n",
       "526913 2014-10-26         45       108\n",
       "526914 2014-10-26         45       109\n",
       "526915 2014-10-26         45       110\n",
       "526916 2014-10-26         45       111"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['date'] = pd.to_datetime(test['date'])\n",
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "\n",
    "test_ = test_preprocessing(test, holiday, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 dataframe별로 뒤에 붙는 숫자에 주의해야함\n",
    "- station_nbr 기준인지 store_nbr 기준인지..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr별 특징\n",
    "- no depart value : 1, 7, 8, 9, 10, 12, 13, 16, 17, 20\n",
    "    - drop??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 1\n",
    "- store_nbr == 1\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_1 = get_item_nbr(train_new_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1036: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              log_units   R-squared:                       0.832\n",
      "Model:                            OLS   Adj. R-squared:                  0.832\n",
      "Method:                 Least Squares   F-statistic:                     2121.\n",
      "Date:                Tue, 06 Mar 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:05:01   Log-Likelihood:                 21988.\n",
      "No. Observations:               50505   AIC:                        -4.374e+04\n",
      "Df Residuals:                   50386   BIC:                        -4.269e+04\n",
      "Df Model:                         118                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "C(weekday)[0]         -0.0029      0.008     -0.390      0.696      -0.018       0.012\n",
      "C(weekday)[1]         -0.0077      0.008     -1.021      0.307      -0.023       0.007\n",
      "C(weekday)[2]         -0.0043      0.008     -0.567      0.571      -0.019       0.011\n",
      "C(weekday)[3]         -0.0019      0.008     -0.254      0.799      -0.017       0.013\n",
      "C(weekday)[4]          0.0020      0.008      0.261      0.794      -0.013       0.017\n",
      "C(weekday)[5]          0.0083      0.008      1.103      0.270      -0.006       0.023\n",
      "C(weekday)[6]          0.0060      0.008      0.793      0.428      -0.009       0.021\n",
      "C(holiday)[T.True]    -0.0012      0.003     -0.359      0.719      -0.008       0.006\n",
      "C(item_nbr)[T.2]    7.929e-16      0.010   7.63e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.3]    2.626e-15      0.010   2.53e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.4]    7.774e-16      0.010   7.48e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.5]   -5.968e-18      0.010  -5.74e-16      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.6]    1.917e-15      0.010   1.84e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.7]   -2.692e-16      0.010  -2.59e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.8]    1.711e-15      0.010   1.65e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.9]       3.2765      0.010    315.289      0.000       3.256       3.297\n",
      "C(item_nbr)[T.10]   4.037e-16      0.010   3.88e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.11]  -8.285e-16      0.010  -7.97e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.12]   1.222e-15      0.010   1.18e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.13]  -9.041e-16      0.010   -8.7e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.14]   9.599e-17      0.010   9.24e-15      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.15]  -1.546e-15      0.010  -1.49e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.16]   1.966e-16      0.010   1.89e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.17]   5.762e-16      0.010   5.54e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.18]  -1.507e-15      0.010  -1.45e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.19]   8.214e-16      0.010    7.9e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.20]   5.256e-16      0.010   5.06e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.21]   9.311e-16      0.010   8.96e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.22]    4.55e-16      0.010   4.38e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.23]  -3.778e-16      0.010  -3.64e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.24]   1.784e-15      0.010   1.72e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.25]    7.74e-16      0.010   7.45e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.26]   9.867e-17      0.010   9.49e-15      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.27]  -4.466e-16      0.010   -4.3e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.28]      1.5612      0.010    150.232      0.000       1.541       1.582\n",
      "C(item_nbr)[T.29]  -9.312e-16      0.010  -8.96e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.30]  -1.061e-15      0.010  -1.02e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.31]  -2.575e-17      0.010  -2.48e-15      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.32]  -3.965e-16      0.010  -3.82e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.33]   2.459e-15      0.010   2.37e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.34]   1.004e-15      0.010   9.66e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.35]   8.583e-16      0.010   8.26e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.36]   6.342e-16      0.010    6.1e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.37]   6.899e-16      0.010   6.64e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.38]  -1.536e-15      0.010  -1.48e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.39]  -2.299e-16      0.010  -2.21e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.40]      0.1433      0.010     13.785      0.000       0.123       0.164\n",
      "C(item_nbr)[T.41]  -1.057e-15      0.010  -1.02e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.42]   1.505e-15      0.010   1.45e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.43]   3.422e-16      0.010   3.29e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.44]  -7.192e-16      0.010  -6.92e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.45]   2.616e-17      0.010   2.52e-15      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.46]   1.831e-16      0.010   1.76e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.47]  -1.737e-15      0.010  -1.67e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.48]   1.463e-15      0.010   1.41e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.49]   1.239e-15      0.010   1.19e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.50]   6.342e-16      0.010    6.1e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.51]      0.4080      0.010     39.261      0.000       0.388       0.428\n",
      "C(item_nbr)[T.52]   5.036e-16      0.010   4.85e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.53]   7.487e-16      0.010    7.2e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.54]  -7.437e-16      0.010  -7.16e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.55]  -9.889e-18      0.010  -9.52e-16      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.56]   -1.06e-15      0.010  -1.02e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.57]   1.746e-15      0.010   1.68e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.58]  -2.098e-16      0.010  -2.02e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.59]  -5.535e-16      0.010  -5.33e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.60]   2.911e-15      0.010    2.8e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.61]   8.648e-16      0.010   8.32e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.62]  -1.657e-16      0.010  -1.59e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.63]   2.288e-15      0.010    2.2e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.64]  -7.767e-16      0.010  -7.47e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.65]   -1.08e-15      0.010  -1.04e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.66]   2.566e-16      0.010   2.47e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.67]   8.357e-16      0.010   8.04e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.68]    -4.6e-16      0.010  -4.43e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.69]    3.38e-16      0.010   3.25e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.70]   7.603e-16      0.010   7.32e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.71]   7.763e-16      0.010   7.47e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.72]  -4.044e-16      0.010  -3.89e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.73]   -9.76e-16      0.010  -9.39e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.74]   1.469e-16      0.010   1.41e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.75]   1.358e-16      0.010   1.31e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.76]   2.547e-16      0.010   2.45e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.77]    4.77e-16      0.010   4.59e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.78]  -4.529e-16      0.010  -4.36e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.79]  -1.252e-15      0.010   -1.2e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.80]   1.138e-15      0.010   1.09e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.81]  -4.072e-16      0.010  -3.92e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.82]   5.516e-16      0.010   5.31e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.83]   1.596e-16      0.010   1.54e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.84]   6.703e-16      0.010   6.45e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.85]  -1.399e-16      0.010  -1.35e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.86]   5.833e-16      0.010   5.61e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.87]   -4.09e-16      0.010  -3.94e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.88]  -9.072e-16      0.010  -8.73e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.89]      0.1410      0.010     13.573      0.000       0.121       0.161\n",
      "C(item_nbr)[T.90]  -4.555e-16      0.010  -4.38e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.91]     9.1e-17      0.010   8.76e-15      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.92]   6.785e-17      0.010   6.53e-15      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.93]      0.6968      0.010     67.048      0.000       0.676       0.717\n",
      "C(item_nbr)[T.94]   1.248e-15      0.010    1.2e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.95]  -3.322e-16      0.010   -3.2e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.96]  -7.884e-16      0.010  -7.59e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.97]     1.8e-16      0.010   1.73e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.98]   4.763e-16      0.010   4.58e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.99]      0.0293      0.010      2.821      0.005       0.009       0.050\n",
      "C(item_nbr)[T.100]   6.89e-17      0.010   6.63e-15      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.101] -7.765e-16      0.010  -7.47e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.102]  5.053e-16      0.010   4.86e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.103] -1.309e-16      0.010  -1.26e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.104] -6.658e-16      0.010  -6.41e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.105] -3.874e-16      0.010  -3.73e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.106] -1.476e-15      0.010  -1.42e-13      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.107]   4.33e-18      0.010   4.17e-16      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.108] -3.119e-16      0.010     -3e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.109]  2.901e-16      0.010   2.79e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.110]  4.517e-16      0.010   4.35e-14      1.000      -0.020       0.020\n",
      "C(item_nbr)[T.111]  1.055e-15      0.010   1.01e-13      1.000      -0.020       0.020\n",
      "snowfall                    0          0        nan        nan           0           0\n",
      "preciptotal            0.0014      0.003      0.425      0.671      -0.005       0.008\n",
      "==============================================================================\n",
      "Omnibus:                    45131.516   Durbin-Watson:                   2.002\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         23763697.707\n",
      "Skew:                           3.350   Prob(JB):                         0.00\n",
      "Kurtosis:                     109.055   Cond. No.                     1.07e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.2e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "test_1 = test_[test_['station_nbr'] == 1]\n",
    "\n",
    "test_1['weekday'] = test_1.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_1['holiday'] = test_1.date.isin(holiday[0])\n",
    "\n",
    "train_new_1['date'] = pd.to_datetime(train_new_1['date'])\n",
    "\n",
    "df = pd.merge(train_new_1, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_1, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_1.reset_index(drop = True, inplace = True)\n",
    "test_1['log_units'] = result_model.predict(test_1)\n",
    "test_1['units'] = np.exp(test_1['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_1)) :\n",
    "    if test_1.at[num, 'item_nbr'] not in item_nbr_list_1 :\n",
    "        test_1.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  station_nbr == 2\n",
    "- store_nbr == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_2 = get_item_nbr(train_new_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = test_[test_['station_nbr'] == 2]\n",
    "\n",
    "test_2['weekday'] = test_2.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_2['holiday'] = test_2.date.isin(holiday[0])\n",
    "\n",
    "train_new_16['date'] = pd.to_datetime(train_new_16['date'])\n",
    "\n",
    "df = pd.merge(train_new_16, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_2, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_2.reset_index(drop = True, inplace = True)\n",
    "test_2['log_units'] = result_model.predict(test_2)\n",
    "test_2['units'] = np.exp(test_2['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_2)) :\n",
    "    if test_2.at[num, 'item_nbr'] not in item_nbr_list_2 :\n",
    "        test_2.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 3\n",
    "- store_nbr == 21, 29, 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_21, train_new_29, train_new_33])\n",
    "item_nbr_list_3 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = test_[test_['station_nbr'] == 3]\n",
    "\n",
    "test_3['weekday'] = test_3.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_3['holiday'] = test_3.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_3, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_3.reset_index(drop = True, inplace = True)\n",
    "test_3['log_units'] = result_model.predict(test_3)\n",
    "test_3['units'] = np.exp(test_3['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_3)) :\n",
    "    if test_3.at[num, 'item_nbr'] not in item_nbr_list_3 :\n",
    "        test_3.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 4\n",
    "- store_nbr == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_4 = get_item_nbr(train_new_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4 = test_[test_['station_nbr'] == 4]\n",
    "\n",
    "test_4['weekday'] = test_4.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_4['holiday'] = test_4.date.isin(holiday[0])\n",
    "\n",
    "train_new_8['date'] = pd.to_datetime(train_new_8['date'])\n",
    "\n",
    "df = pd.merge(train_new_8, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_4, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_4.reset_index(drop = True, inplace = True)\n",
    "test_4['log_units'] = result_model.predict(test_4)\n",
    "test_4['units'] = np.exp(test_4['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_4)) :\n",
    "    if test_4.at[num, 'item_nbr'] not in item_nbr_list_4 :\n",
    "        test_4.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 5\n",
    "- store_nbr == 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 여긴 좀 고민할 필요가 있음..\n",
    "# weather가 죄다 missing value.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_nbr_list_5 = get_item_nbr(train_new_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              log_units   R-squared:                       0.846\n",
      "Model:                            OLS   Adj. R-squared:                  0.846\n",
      "Method:                 Least Squares   F-statistic:                     1577.\n",
      "Date:                Tue, 06 Mar 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:05:18   Log-Likelihood:                 12120.\n",
      "No. Observations:               33633   AIC:                        -2.400e+04\n",
      "Df Residuals:                   33515   BIC:                        -2.301e+04\n",
      "Df Model:                         117                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "C(weekday)[0]         -0.0001      0.010     -0.014      0.989      -0.020       0.019\n",
      "C(weekday)[1]         -0.0035      0.010     -0.346      0.729      -0.023       0.016\n",
      "C(weekday)[2]         -0.0054      0.010     -0.541      0.589      -0.025       0.014\n",
      "C(weekday)[3]         -0.0020      0.010     -0.204      0.839      -0.022       0.018\n",
      "C(weekday)[4]          0.0029      0.010      0.294      0.769      -0.017       0.022\n",
      "C(weekday)[5]          0.0099      0.010      0.993      0.321      -0.010       0.029\n",
      "C(weekday)[6]          0.0002      0.010      0.020      0.984      -0.019       0.020\n",
      "C(holiday)[T.True]    -0.0073      0.004     -1.643      0.100      -0.016       0.001\n",
      "C(item_nbr)[T.2]   -1.426e-15      0.014  -1.04e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.3]    6.668e-16      0.014   4.85e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.4]    1.415e-15      0.014   1.03e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.5]   -4.802e-16      0.014   -3.5e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.6]    6.178e-16      0.014    4.5e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.7]   -1.229e-15      0.014  -8.95e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.8]   -1.934e-15      0.014  -1.41e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.9]   -1.067e-15      0.014  -7.77e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.10]   9.915e-17      0.014   7.22e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.11]   2.218e-16      0.014   1.61e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.12]   2.737e-16      0.014   1.99e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.13]  -5.177e-16      0.014  -3.77e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.14]   1.458e-15      0.014   1.06e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.15]  -1.243e-15      0.014  -9.05e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.16]      3.1009      0.014    225.773      0.000       3.074       3.128\n",
      "C(item_nbr)[T.17]   6.529e-16      0.014   4.75e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.18]   2.868e-15      0.014   2.09e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.19]   6.758e-16      0.014   4.92e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.20]   1.132e-15      0.014   8.24e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.21]   -7.02e-16      0.014  -5.11e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.22]  -1.584e-16      0.014  -1.15e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.23]  -3.229e-15      0.014  -2.35e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.24]      0.7967      0.014     58.005      0.000       0.770       0.824\n",
      "C(item_nbr)[T.25]  -8.716e-16      0.014  -6.35e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.26]  -3.946e-15      0.014  -2.87e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.27]  -1.142e-16      0.014  -8.32e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.28]   1.137e-16      0.014   8.28e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.29]  -8.124e-16      0.014  -5.91e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.30]   1.547e-15      0.014   1.13e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.31]  -5.592e-16      0.014  -4.07e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.32]  -4.775e-17      0.014  -3.48e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.33]   1.971e-15      0.014   1.44e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.34]   7.503e-16      0.014   5.46e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.35]    3.57e-16      0.014    2.6e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.36]   1.671e-16      0.014   1.22e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.37]  -1.132e-15      0.014  -8.24e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.38]  -2.831e-16      0.014  -2.06e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.39]   7.462e-16      0.014   5.43e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.40]   1.946e-15      0.014   1.42e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.41]  -5.276e-16      0.014  -3.84e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.42]   4.118e-16      0.014      3e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.43]  -6.238e-16      0.014  -4.54e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.44]    1.74e-16      0.014   1.27e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.45]   8.972e-16      0.014   6.53e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.46]  -8.097e-16      0.014   -5.9e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.47]   1.573e-17      0.014   1.15e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.48]   -2.22e-15      0.014  -1.62e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.49]      0.1015      0.014      7.387      0.000       0.075       0.128\n",
      "C(item_nbr)[T.50]      0.2659      0.014     19.358      0.000       0.239       0.293\n",
      "C(item_nbr)[T.51]    6.98e-16      0.014   5.08e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.52]  -1.712e-16      0.014  -1.25e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.53]   2.861e-16      0.014   2.08e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.54]   3.486e-16      0.014   2.54e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.55]  -2.908e-16      0.014  -2.12e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.56]  -1.638e-16      0.014  -1.19e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.57]  -8.401e-16      0.014  -6.12e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.58]   4.787e-16      0.014   3.49e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.59]   2.337e-16      0.014    1.7e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.60]    5.18e-16      0.014   3.77e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.61]  -1.286e-16      0.014  -9.36e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.62]   7.929e-16      0.014   5.77e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.63]      0.3014      0.014     21.947      0.000       0.275       0.328\n",
      "C(item_nbr)[T.64]   1.509e-15      0.014    1.1e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.65]  -3.914e-16      0.014  -2.85e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.66]      2.6956      0.014    196.263      0.000       2.669       2.723\n",
      "C(item_nbr)[T.67]   1.893e-16      0.014   1.38e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.68]   6.721e-16      0.014   4.89e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.69]  -8.256e-17      0.014  -6.01e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.70]    6.64e-16      0.014   4.83e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.71]  -2.832e-17      0.014  -2.06e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.72]  -2.984e-15      0.014  -2.17e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.73]  -1.374e-15      0.014     -1e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.74]    7.89e-16      0.014   5.74e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.75]   2.614e-16      0.014    1.9e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.76]   4.045e-16      0.014   2.94e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.77]   1.445e-17      0.014   1.05e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.78]   5.334e-16      0.014   3.88e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.79]   1.185e-15      0.014   8.63e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.80]   7.532e-16      0.014   5.48e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.81]   9.909e-16      0.014   7.21e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.82]   1.425e-16      0.014   1.04e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.83]   1.516e-15      0.014    1.1e-13      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.84]   1.231e-16      0.014   8.96e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.85]   1.149e-15      0.014   8.37e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.86]    3.01e-16      0.014   2.19e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.87]   5.979e-16      0.014   4.35e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.88]  -3.875e-16      0.014  -2.82e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.89]    1.04e-15      0.014   7.57e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.90]  -1.339e-16      0.014  -9.75e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.91]   1.822e-16      0.014   1.33e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.92]   -1.83e-16      0.014  -1.33e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.93]      0.5010      0.014     36.477      0.000       0.474       0.528\n",
      "C(item_nbr)[T.94]   3.054e-16      0.014   2.22e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.95]   4.269e-16      0.014   3.11e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.96]   2.753e-17      0.014      2e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.97]   6.479e-18      0.014   4.72e-16      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.98]   4.143e-16      0.014   3.02e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.99]   5.691e-17      0.014   4.14e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.100]  4.901e-16      0.014   3.57e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.101] -3.361e-17      0.014  -2.45e-15      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.102] -2.911e-16      0.014  -2.12e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.103]  -1.98e-16      0.014  -1.44e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.104] -1.511e-16      0.014   -1.1e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.105]  3.561e-16      0.014   2.59e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.106]  9.368e-16      0.014   6.82e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.107]  9.314e-16      0.014   6.78e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.108]  6.978e-16      0.014   5.08e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.109]  7.721e-16      0.014   5.62e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.110]  1.826e-16      0.014   1.33e-14      1.000      -0.027       0.027\n",
      "C(item_nbr)[T.111]  6.261e-16      0.014   4.56e-14      1.000      -0.027       0.027\n",
      "snowfall                    0          0        nan        nan           0           0\n",
      "preciptotal                 0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                    40931.532   Durbin-Watson:                   1.922\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         22994157.652\n",
      "Skew:                           6.023   Prob(JB):                         0.00\n",
      "Kurtosis:                     130.527   Cond. No.                     1.04e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.87e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1036: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "test_5 = test_[test_['station_nbr'] == 5]\n",
    "\n",
    "test_5['weekday'] = test_5.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_5['holiday'] = test_5.date.isin(holiday[0])\n",
    "\n",
    "train_new_35['date'] = pd.to_datetime(train_new_35['date'])\n",
    "\n",
    "df = pd.merge(train_new_35, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_5, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_5.reset_index(drop = True, inplace = True)\n",
    "test_5['log_units'] = result_model.predict(test_5)\n",
    "test_5['units'] = np.exp(test_5['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_5)) :\n",
    "    if test_5.at[num, 'item_nbr'] not in item_nbr_list_5 :\n",
    "        test_5.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 6\n",
    "- store_nbr == 7, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_7, train_new_13])\n",
    "item_nbr_list_6 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_6 = test_[test_['station_nbr'] == 6]\n",
    "\n",
    "test_6['weekday'] = test_6.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_6['holiday'] = test_6.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_6, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_6.reset_index(drop = True, inplace = True)\n",
    "test_6['log_units'] = result_model.predict(test_6)\n",
    "test_6['units'] = np.exp(test_6['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_6)) :\n",
    "    if test_6.at[num, 'item_nbr'] not in item_nbr_list_6 :\n",
    "        test_6.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 7\n",
    "- store_nbr == 3, 20, 28\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_3, train_new_20, train_new_28])\n",
    "item_nbr_list_7 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_7 = test_[test_['station_nbr'] == 7]\n",
    "\n",
    "test_7['weekday'] = test_7.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_7['holiday'] = test_7.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_7, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_7.reset_index(drop = True, inplace = True)\n",
    "test_7['log_units'] = result_model.predict(test_7)\n",
    "test_7['units'] = np.exp(test_7['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_7)) :\n",
    "    if test_7.at[num, 'item_nbr'] not in item_nbr_list_7 :\n",
    "        test_7.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 8\n",
    "- store_nbr == 39\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_8 = get_item_nbr(train_new_39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_8 = test_[test_['station_nbr'] == 8]\n",
    "\n",
    "test_8['weekday'] = test_8.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_8['holiday'] = test_8.date.isin(holiday[0])\n",
    "\n",
    "train_new_39['date'] = pd.to_datetime(train_new_39['date'])\n",
    "\n",
    "df = pd.merge(train_new_39, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_8, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_8.reset_index(drop = True, inplace = True)\n",
    "test_8['log_units'] = result_model.predict(test_8)\n",
    "test_8['units'] = np.exp(test_8['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_8)) :\n",
    "    if test_8.at[num, 'item_nbr'] not in item_nbr_list_8 :\n",
    "        test_8.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 9\n",
    "- store_nbr == 4, 24\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_4, train_new_24])\n",
    "item_nbr_list_9 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_9 = test_[test_['station_nbr'] == 9]\n",
    "\n",
    "test_9['weekday'] = test_9.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_9['holiday'] = test_9.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_9, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_9.reset_index(drop = True, inplace = True)\n",
    "test_9['log_units'] = result_model.predict(test_9)\n",
    "test_9['units'] = np.exp(test_9['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_9)) :\n",
    "    if test_9.at[num, 'item_nbr'] not in item_nbr_list_9 :\n",
    "        test_9.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 10\n",
    "- store_nbr == 11, 22, 27\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_11, train_new_22, train_new_27])\n",
    "item_nbr_list_10 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_10 = test_[test_['station_nbr'] == 10]\n",
    "\n",
    "test_10['weekday'] = test_10.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_10['holiday'] = test_10.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_10, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_10.reset_index(drop = True, inplace = True)\n",
    "test_10['log_units'] = result_model.predict(test_10)\n",
    "test_10['units'] = np.exp(test_10['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_10)) :\n",
    "    if test_10.at[num, 'item_nbr'] not in item_nbr_list_10 :\n",
    "        test_10.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 11\n",
    "- store_nbr == 12, 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_12, train_new_43])\n",
    "item_nbr_list_11 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_11 = test_[test_['station_nbr'] == 11]\n",
    "\n",
    "test_11['weekday'] = test_11.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_11['holiday'] = test_11.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_11, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_11.reset_index(drop = True, inplace = True)\n",
    "test_11['log_units'] = result_model.predict(test_11)\n",
    "test_11['units'] = np.exp(test_11['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_11)) :\n",
    "    if test_11.at[num, 'item_nbr'] not in item_nbr_list_11 :\n",
    "        test_11.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 12\n",
    "- store_nbr == 5, 10, 41, 44\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_5, train_new_10, train_new_41, train_new_44])\n",
    "item_nbr_list_12 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_12 = test_[test_['station_nbr'] == 12]\n",
    "\n",
    "test_12['weekday'] = test_12.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_12['holiday'] = test_12.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_12, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_12.reset_index(drop = True, inplace = True)\n",
    "test_12['log_units'] = result_model.predict(test_12)\n",
    "test_12['units'] = np.exp(test_12['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_12)) :\n",
    "    if test_12.at[num, 'item_nbr'] not in item_nbr_list_12 :\n",
    "        test_12.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 13\n",
    "- store_nbr == 15, 25, 32, 37, 40\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_15, train_new_25, train_new_32, train_new_37, train_new_40])\n",
    "item_nbr_list_13 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_13 = test_[test_['station_nbr'] == 13]\n",
    "\n",
    "test_13['weekday'] = test_13.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_13['holiday'] = test_13.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_13, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_13.reset_index(drop = True, inplace = True)\n",
    "test_13['log_units'] = result_model.predict(test_13)\n",
    "test_13['units'] = np.exp(test_13['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_13)) :\n",
    "    if test_13.at[num, 'item_nbr'] not in item_nbr_list_13 :\n",
    "        test_13.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 14\n",
    "- store_nbr == 2, 6, 38, 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_2, train_new_6, train_new_38, train_new_42])\n",
    "item_nbr_list_14 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_14 = test_[test_['station_nbr'] == 14]\n",
    "\n",
    "test_14['weekday'] = test_14.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_14['holiday'] = test_14.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_14, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_14.reset_index(drop = True, inplace = True)\n",
    "test_14['log_units'] = result_model.predict(test_14)\n",
    "test_14['units'] = np.exp(test_14['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_14)) :\n",
    "    if test_14.at[num, 'item_nbr'] not in item_nbr_list_14 :\n",
    "        test_14.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 15\n",
    "- store_nbr == 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_15 = get_item_nbr(train_new_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_15 = test_[test_['station_nbr'] == 15]\n",
    "\n",
    "test_15['weekday'] = test_15.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_15['holiday'] = test_15.date.isin(holiday[0])\n",
    "\n",
    "train_new_19['date'] = pd.to_datetime(train_new_19['date'])\n",
    "\n",
    "df = pd.merge(train_new_19, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_15, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_15.reset_index(drop = True, inplace = True)\n",
    "test_15['log_units'] = result_model.predict(test_15)\n",
    "test_15['units'] = np.exp(test_15['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_15)) :\n",
    "    if test_15.at[num, 'item_nbr'] not in item_nbr_list_15 :\n",
    "        test_15.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 16\n",
    "- store_nbr == 14, 45\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_14, train_new_45])\n",
    "item_nbr_list_16 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_16 = test_[test_['station_nbr'] == 16]\n",
    "\n",
    "test_16['weekday'] = test_16.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_16['holiday'] = test_16.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_16, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_16.reset_index(drop = True, inplace = True)\n",
    "test_16['log_units'] = result_model.predict(test_16)\n",
    "test_16['units'] = np.exp(test_16['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_16)) :\n",
    "    if test_16.at[num, 'item_nbr'] not in item_nbr_list_16 :\n",
    "        test_16.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 17\n",
    "- store_nbr == 9, 18, 23, 26, 31, 34\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_9, train_new_18, train_new_23, train_new_26, train_new_31, train_new_34])\n",
    "result1 = pd.concat([train_new_9, train_new_18, train_new_23])\n",
    "result2 = pd.concat([train_new_26, train_new_31, train_new_34])\n",
    "item_nbr_list_17 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_17 = test_[test_['station_nbr'] == 17]\n",
    "\n",
    "test_17['weekday'] = test_17.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_17['holiday'] = test_17.date.isin(holiday[0])\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "df = pd.merge(result, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_17, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + C(event) + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_17.reset_index(drop = True, inplace = True)\n",
    "test_17['log_units'] = result_model.predict(test_17)\n",
    "test_17['units'] = np.exp(test_17['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_17)) :\n",
    "    if test_17.at[num, 'item_nbr'] not in item_nbr_list_17 :\n",
    "        test_17.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_1 = test_[test_['station_nbr'] == 17]\n",
    "list_17_1 = [9, 18, 23]\n",
    "\n",
    "for num in list_17_1 :\n",
    "    test_17_1 = pd.concat([test_17_1[test_17_1['store_nbr'] == num] for num in list_17_1])\n",
    "\n",
    "test_17_1['weekday'] = test_17_1.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_17_1['holiday'] = test_17_1.date.isin(holiday[0])\n",
    "\n",
    "result1['date'] = pd.to_datetime(result1['date'])\n",
    "\n",
    "df = pd.merge(result1, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_17, on = ['date', 'station_nbr'])\n",
    "\n",
    "model1 = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model1 = model1.fit()\n",
    "print(result_model1.summary())\n",
    "\n",
    "test_17_1.reset_index(drop = True, inplace = True)\n",
    "test_17_1['log_units'] = result_model1.predict(test_17_1)\n",
    "test_17_1['units'] = np.exp(test_17_1['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_17_1)) :\n",
    "    if test_17_1.at[num, 'item_nbr'] not in item_nbr_list_17 :\n",
    "        test_17_1.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_2 = test_[test_['station_nbr'] == 17]\n",
    "list_17_2 = [26, 31, 34]\n",
    "\n",
    "for num in list_17_2 :\n",
    "    test_17_2 = pd.concat([test_17_2[test_17_2['store_nbr'] == num] for num in list_17_2])\n",
    "\n",
    "test_17_2['weekday'] = test_17_2.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_17_2['holiday'] = test_17_2.date.isin(holiday[0])\n",
    "\n",
    "result2['date'] = pd.to_datetime(result2['date'])\n",
    "\n",
    "df = pd.merge(result2, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_17, on = ['date', 'station_nbr'])\n",
    "\n",
    "model2 = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model2 = model2.fit()\n",
    "print(result_model2.summary())\n",
    "\n",
    "test_17_2.reset_index(drop = True, inplace = True)\n",
    "test_17_2['log_units'] = result_model2.predict(test_17_2)\n",
    "test_17_2['units'] = np.exp(test_17_2['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_17_2)) :\n",
    "    if test_17_2.at[num, 'item_nbr'] not in item_nbr_list_17 :\n",
    "        test_17_2.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_17_1)\n",
    "result_test.append(test_17_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 18\n",
    "- store_nbr == 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_18 = get_item_nbr(train_new_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_18 = test_[test_['station_nbr'] == 18]\n",
    "\n",
    "test_18['weekday'] = test_18.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_18['holiday'] = test_18.date.isin(holiday[0])\n",
    "\n",
    "train_new_36['date'] = pd.to_datetime(train_new_36['date'])\n",
    "\n",
    "df = pd.merge(train_new_36, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_18, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_18.reset_index(drop = True, inplace = True)\n",
    "test_18['log_units'] = result_model.predict(test_18)\n",
    "test_18['units'] = np.exp(test_18['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_18)) :\n",
    "    if test_18.at[num, 'item_nbr'] not in item_nbr_list_18 :\n",
    "        test_18.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 19\n",
    "- store_nbr == 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_19 = get_item_nbr(train_new_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_19 = test_[test_['station_nbr'] == 19]\n",
    "\n",
    "test_19['weekday'] = test_19.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_19['holiday'] = test_19.date.isin(holiday[0])\n",
    "\n",
    "train_new_30['date'] = pd.to_datetime(train_new_30['date'])\n",
    "\n",
    "df = pd.merge(train_new_30, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_19, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_19.reset_index(drop = True, inplace = True)\n",
    "test_19['log_units'] = result_model.predict(test_19)\n",
    "test_19['units'] = np.exp(test_19['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_19)) :\n",
    "    if test_19.at[num, 'item_nbr'] not in item_nbr_list_19 :\n",
    "        test_19.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 20\n",
    "- store_nbr == 17\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_nbr_list_20 = get_item_nbr(train_new_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_20 = test_[test_['station_nbr'] == 20]\n",
    "\n",
    "test_20['weekday'] = test_20.date.dt.weekday  # 월요일이 0 일요일이 8\n",
    "test_20['holiday'] = test_20.date.isin(holiday[0])\n",
    "\n",
    "train_new_17['date'] = pd.to_datetime(train_new_17['date'])\n",
    "\n",
    "df = pd.merge(train_new_17, key, on = 'store_nbr')\n",
    "df = pd.merge(df, weather_train_20, on = ['date', 'station_nbr'])\n",
    "\n",
    "model = sm.OLS.from_formula('log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + snowfall + preciptotal + 0', data = df)\n",
    "result_model = model.fit()\n",
    "print(result_model.summary())\n",
    "\n",
    "test_20.reset_index(drop = True, inplace = True)\n",
    "test_20['log_units'] = result_model.predict(test_20)\n",
    "test_20['units'] = np.exp(test_20['log_units']) - 1\n",
    "\n",
    "for num in range(len(test_20)) :\n",
    "    if test_20.at[num, 'item_nbr'] not in item_nbr_list_20 :\n",
    "        test_20.set_value(num, 'units', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_test.append(test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression, OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dep. Variable : Which variable is the response in the model\n",
    "\n",
    "- Model : What model you are using in the fit\n",
    "\n",
    "- Method : How the parameters of the model were calculated\n",
    "\n",
    "- No. Observations : The number of observations (examples)\n",
    "- DF Residuals : Degrees of freedom of the residuals. Number of observations – number of parameters\n",
    "- DF Model : Number of parameters in the model (not including the constant term if present)\n",
    "\n",
    "#### The right part of the first table shows the goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second table reports for each of the coefficients\n",
    "\n",
    "- R-squared : The coefficient of determination. A statistical measure of how well the regression line approximates the real data points\n",
    "    \n",
    "- Adj. R-squared : The above value adjusted based on the number of observations and the degrees-of-freedom of the residuals\n",
    "- F-statistic : A measure how significant the fit is. The mean squared error of the model divided by the mean squared error of the residuals\n",
    "- Prob (F-statistic) : The probability that you would get the above statistic, given the null hypothesis that they are unrelated\n",
    "- Log-likelihood : The log of the likelihood function.\n",
    "- AIC : The Akaike Information Criterion. Adjusts the log-likelihood based on the number of observations and the complexity of the model.\n",
    "- BIC : The Bayesian Information Criterion. Similar to the AIC, but has a higher penalty for models with more parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test = pd.concat(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test.drop(['weekday', 'weekend', 'holiday', 'station_nbr', 'event', 'log_units'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.drop(['weekday', 'weekend', 'holiday', 'station_nbr', 'event', 'snowfall', 'preciptotal', 'log_units'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test.sort_values(by = ['date', 'store_nbr', 'item_nbr'], inplace = True)\n",
    "sub_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num in range(len(sub_test)) :\n",
    "    if sub_test.at[num, 'date'] == '2013-12-25' :\n",
    "        sub_test.set_value(num, 'date', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units = sub_test['units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test['date'] = sub_test['date'].astype('str')\n",
    "sub_test['store_nbr'] = sub_test['store_nbr'].astype('str')\n",
    "sub_test['item_nbr'] = sub_test['item_nbr'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test['id'] = sub_test['store_nbr'] + '_' + sub_test['item_nbr'] + '_' + sub_test['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test.drop(['date', 'store_nbr', 'item_nbr', 'units'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test['units'] = units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test.to_csv('sub_test6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_units ~ C(store_nbr) + C(weekday) + C(holiday) + C(event) + C(item_nbr) + 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub_test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../sub_test3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../sub_test3_rank.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_units ~ C(store_nbr):C(item_nbr) + C(weekday) + C(holiday) + C(event) + 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub_test4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../sub_test4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../sub_test4_rank.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub_test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
