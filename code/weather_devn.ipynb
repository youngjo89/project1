{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = pd.read_csv('../data/key.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "weather = pd.read_csv('../data/weather.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>log_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4617595</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617596</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617597</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617598</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617599</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  units  log_units\n",
       "4617595  2014-10-31         45       107      0        0.0\n",
       "4617596  2014-10-31         45       108      0        0.0\n",
       "4617597  2014-10-31         45       109      0        0.0\n",
       "4617598  2014-10-31         45       110      0        0.0\n",
       "4617599  2014-10-31         45       111      0        0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['log_units'] = np.log(train['units'] + 1)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new = train[:2255853] # 2013년 3월 31일까지의 train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_train = weather[:8968] # 2013년 3월 31일까지의 weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather 관련 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weather_train(df, station_nbr) : # staion_nbr에 따라서 weather train dataframe을 만드는 함수\n",
    "    new_df = df[df['station_nbr'] == station_nbr]\n",
    "    new_df.reset_index(drop = True, inplace = True)\n",
    "    return new_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_tmax(df) : # tmax의 missing value를 처리하는 함수\n",
    "    for num in range(len(df)) :  # tmax의 missing value 처리,,, 이틀 전날의 0.2배 + 하루 전날의 0.8배\n",
    "        if df.at[num, 'tmax'] == 'M' :\n",
    "            df.set_value(num, 'tmax', int(0.2 * int(df.at[num - 2, 'tmax']) + 0.8 * int(df.at[num - 1, 'tmax'])))\n",
    "        \n",
    "        else :\n",
    "            df.at[num, 'tmax'] = int(df.at[num, 'tmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_tmin(df) : # tmin의 missing value를 처리하는 함수\n",
    "    for num in range(len(df)) :  # tmax의 missing value 처리,,, 이틀 전날의 0.2배 + 하루 전날의 0.8배\n",
    "        if df.at[num, 'tmin'] == 'M' :\n",
    "            df.set_value(num, 'tmin', int(0.2 * int(df.at[num - 2, 'tmin']) + 0.8 * int(df.at[num - 1, 'tmin'])))\n",
    "            \n",
    "        else :\n",
    "            df.at[num,'tmin'] = int(df.at[num, 'tmin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_tavg(df) : # tavg의 값을 처리하는 함수\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'tavg'] == 'M' :\n",
    "            df.set_value(num, 'tavg', int((df.at[num, 'tmax'] + df.at[num, 'tmin']) / 2)) # (tmax + tmin) / 2\n",
    "            \n",
    "        else :\n",
    "            df.at[num, 'tavg'] = int(df.at[num, 'tavg'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_depart(df) : # how can I get depart value..wtf\n",
    "    if df.at[0, 'depart'] == 'M' :\n",
    "        print(\"Cannot get depart value\") # depart값을 구할 수 없는 경우\n",
    "            \n",
    "    else :\n",
    "        depart_base = int(df.at[0, 'tavg']) - int(df.at[0, 'depart']) # 각 weather station을 보면 tavg - depart값이 일정하다.. 개이득..\n",
    "        for num in range(1, len(df)) :\n",
    "            df.set_value(num, 'depart', int((df.at[num, 'tavg'] - depart_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_dewpoint(df) : \n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'dewpoint'] == 'M' :\n",
    "            df.set_value(num, 'dewpoint', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_wetbulb(df) : # 습구온도는 불포화공기에서는 건구온도보다 낮고 노점(이슬점, dewpoint)보다 높지만, 포화공기에서 3자는 일치한다.\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'wetbulb'] == 'M' :\n",
    "            df.set_value(num, 'wetbulb', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_heat_cool(df) : # heat, cool의 missing value 처리\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'heat'] == 'M' or df.at[num, 'cool'] == 'M' :\n",
    "            \n",
    "            if df.at[num, 'tavg'] == 65 : # tavg == 65 이면 heat, cool 모두 0\n",
    "                df.set_value(num, 'heat', 0)\n",
    "                df.set_value(num, 'cool', 0)\n",
    "            \n",
    "            elif df.at[num, 'tavg'] > 65 : #tavg > 65 이면 heat = 0, cool = tavg - 65\n",
    "                df.set_value(num, 'heat', 0)\n",
    "                df.set_value(num, 'cool', df.at[num, 'tavg'] - 65)\n",
    "            \n",
    "            else : #tavg < 65 이면 heat = 65 - tavg, cool = 0\n",
    "                df.set_value(num, 'heat', 65 - df.at[num, 'tavg'])\n",
    "                df.set_value(num, 'cool', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_heat_cool(df) :\n",
    "    df['heat_cool'] = \"\"\n",
    "    \n",
    "    for num in range(len(df)) :\n",
    "        df.set_value(num, \"heat_cool\", int(df.at[num, \"cool\"]) - int(df.at[num, \"heat\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_snowfall_preciptotal(df) : #codesum에 RA가 있는데 preciptotal이 T인경우도있다...\n",
    "    for num in range(len(df)) :\n",
    "        if ('T' in df.at[num, 'snowfall']) or ('M' in df.at[num, 'snowfall']) : # snowfall이 trace or M이면 0으로 setting\n",
    "            df.set_value(num, 'snowfall', 0.0)\n",
    "        \n",
    "        if ('T' in df.at[num, 'preciptotal']) or ('M' in df.at[num, 'preciptotal']) : # preciptotal이 trace or M이면 0으로 setting\n",
    "            df.set_value(num, 'preciptotal', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_stnpressure(df) :\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'stnpressure'] == 'M' :\n",
    "            df.set_value(num, 'stnpressure', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_sealevel(df) :\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'sealevel'] == 'M' :\n",
    "            df.set_value(num, 'sealevel', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_resultspeed(df) : # 바람관련 column 3개는 어떤 연관관계가 있지않을까..\n",
    "#     The fastest 2-minute (average) wind speed, in Miles Per Hour.\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'resultspeed'] == 'M' :\n",
    "            df.set_value(num, 'resultspeed', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_resultdir(df) :\n",
    "#     resultdir : The direction the fastest 2-minute wind was blowing FROM in tens of degrees\n",
    "#     27 would be 270 degrees = wind was blowing from the west to the east\n",
    "#     (36 = North, 09 = East, 18 = South, 27 = West)\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'resultdir'] == 'M' :\n",
    "            df.set_value(num, 'resultdir', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_avgspeed(df) :\n",
    "#     The average wind speed for the day, in Miles Per Hour\n",
    "    for num in range(len(df)) :\n",
    "        if df.at[num, 'avgspeed'] == 'M' :\n",
    "            df.set_value(num, 'avgspeed', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train 관련 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_train(df, store_nbr) : # store_nbr에 따라 train data를 나눠주는 함수\n",
    "    new_df = df[df['store_nbr'] == store_nbr]\n",
    "    new_df.reset_index(drop = True, inplace = True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather와 train data를 합쳐주는 함수\n",
    "- train data 중 log_units != 0 인 item들만 합쳐줌.. (log_units != 0 이면 units != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_weather_train(weather, train) :\n",
    "    train_pivot = train.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "    train_pivot = train_pivot.loc[:, (train_pivot != 0).any(axis = 0)] # log_units이 모두 0인 item_nbr(column)을 삭제..\n",
    "    train_pivot.loc['2012-12-25'] = 0 # 2012-12-25의 data를 0으로 추가... 원래 없었던 data이므로 0으로 설정함\n",
    "    \n",
    "    list_item_nbr = train_pivot.columns # units 전체가 0이 아닌 item_nbr들을 list형태로 받음\n",
    "#     length = len(train_pivot.columns) # units전체가 0이 아닌 item_nbr이 총 몇개 있는지..\n",
    "        \n",
    "    train_pivot.index.name = \"date\"\n",
    "    train_pivot.reset_index(inplace = True)\n",
    "    train_pivot.sort_values(by = 'date', inplace = True)\n",
    "    train_pivot.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    for num in list_item_nbr :\n",
    "        weather[num] = train_pivot[num]\n",
    "    \n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_item_nbr(df) : # 모든 units이 0이 아닌 item_nbr을 구하는 함수, list형태로 return\n",
    "    tmp = df.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "    tmp = tmp.loc[:, (tmp != 0).any(axis = 0)]\n",
    "    tmp.loc['2012-12-25'] = 0 # 2012-12-25가 빠져있음 train data에서.. 그래서 log_units = 0으로 넣어줌.\n",
    "    \n",
    "    tmp.reset_index(inplace = True)\n",
    "    tmp.sort_values(by = 'date', inplace = True)\n",
    "    tmp.drop(['date'], axis = 1, inplace = True)\n",
    "    \n",
    "    result = list(tmp.columns)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#station_nbr로 weather_train을 나눠줌\n",
    "# 박두진 강사님이 이 부분을 줄일 수 있는 방법을 찾아봐주신다 하였음..일단은 그냥 쓰자!\n",
    "\n",
    "weather_train_1 = get_weather_train(weather_train, 1)\n",
    "weather_train_2 = get_weather_train(weather_train, 2)\n",
    "weather_train_3 = get_weather_train(weather_train, 3)\n",
    "weather_train_4 = get_weather_train(weather_train, 4)\n",
    "weather_train_5 = get_weather_train(weather_train, 5) # missing value가 많아서 일단은..\n",
    "weather_train_6 = get_weather_train(weather_train, 6)\n",
    "weather_train_7 = get_weather_train(weather_train, 7)\n",
    "weather_train_8 = get_weather_train(weather_train, 8)\n",
    "weather_train_9 = get_weather_train(weather_train, 9)\n",
    "weather_train_10 = get_weather_train(weather_train, 10)\n",
    "weather_train_11 = get_weather_train(weather_train, 11)\n",
    "weather_train_12 = get_weather_train(weather_train, 12)\n",
    "weather_train_13 = get_weather_train(weather_train, 13)\n",
    "weather_train_14 = get_weather_train(weather_train, 14)\n",
    "weather_train_15 = get_weather_train(weather_train, 15)\n",
    "weather_train_16 = get_weather_train(weather_train, 16)\n",
    "weather_train_17 = get_weather_train(weather_train, 17)\n",
    "weather_train_18 = get_weather_train(weather_train, 18)\n",
    "weather_train_19 = get_weather_train(weather_train, 19)\n",
    "weather_train_20 = get_weather_train(weather_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new_1 = get_train_train(train_new, 1)\n",
    "train_new_2 = get_train_train(train_new, 2)\n",
    "train_new_3 = get_train_train(train_new, 3)\n",
    "train_new_4 = get_train_train(train_new, 4)\n",
    "train_new_5 = get_train_train(train_new, 5)\n",
    "train_new_6 = get_train_train(train_new, 6)\n",
    "train_new_7 = get_train_train(train_new, 7)\n",
    "train_new_8 = get_train_train(train_new, 8)\n",
    "train_new_9 = get_train_train(train_new, 9)\n",
    "train_new_10 = get_train_train(train_new, 10)\n",
    "train_new_11 = get_train_train(train_new, 11)\n",
    "train_new_12 = get_train_train(train_new, 12)\n",
    "train_new_13 = get_train_train(train_new, 13)\n",
    "train_new_14 = get_train_train(train_new, 14)\n",
    "train_new_15 = get_train_train(train_new, 15)\n",
    "train_new_16 = get_train_train(train_new, 16)\n",
    "train_new_17 = get_train_train(train_new, 17)\n",
    "train_new_18 = get_train_train(train_new, 18)\n",
    "train_new_19 = get_train_train(train_new, 19)\n",
    "train_new_20 = get_train_train(train_new, 20)\n",
    "train_new_21 = get_train_train(train_new, 21)\n",
    "train_new_22 = get_train_train(train_new, 22)\n",
    "train_new_23 = get_train_train(train_new, 23)\n",
    "train_new_24 = get_train_train(train_new, 24)\n",
    "train_new_25 = get_train_train(train_new, 25)\n",
    "train_new_26 = get_train_train(train_new, 26)\n",
    "train_new_27 = get_train_train(train_new, 27)\n",
    "train_new_28 = get_train_train(train_new, 28)\n",
    "train_new_29 = get_train_train(train_new, 29)\n",
    "train_new_30 = get_train_train(train_new, 30)\n",
    "train_new_31 = get_train_train(train_new, 31)\n",
    "train_new_32 = get_train_train(train_new, 32)\n",
    "train_new_33 = get_train_train(train_new, 33)\n",
    "train_new_34 = get_train_train(train_new, 34)\n",
    "train_new_35 = get_train_train(train_new, 35)\n",
    "train_new_36 = get_train_train(train_new, 36)\n",
    "train_new_37 = get_train_train(train_new, 37)\n",
    "train_new_38 = get_train_train(train_new, 38)\n",
    "train_new_39 = get_train_train(train_new, 39)\n",
    "train_new_40 = get_train_train(train_new, 40)\n",
    "train_new_41 = get_train_train(train_new, 41)\n",
    "train_new_42 = get_train_train(train_new, 42)\n",
    "train_new_43 = get_train_train(train_new, 43)\n",
    "train_new_44 = get_train_train(train_new, 44)\n",
    "train_new_45 = get_train_train(train_new, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weather_train.sort_values(by = ['station_nbr', 'date'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tavg</th>\n",
       "      <th>depart</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>wetbulb</th>\n",
       "      <th>heat</th>\n",
       "      <th>cool</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "      <th>codesum</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>stnpressure</th>\n",
       "      <th>sealevel</th>\n",
       "      <th>resultspeed</th>\n",
       "      <th>resultdir</th>\n",
       "      <th>avgspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RA FZFG BR</td>\n",
       "      <td>M</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.78</td>\n",
       "      <td>29.92</td>\n",
       "      <td>3.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>0.01</td>\n",
       "      <td>29.44</td>\n",
       "      <td>29.62</td>\n",
       "      <td>9.8</td>\n",
       "      <td>24</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.67</td>\n",
       "      <td>29.87</td>\n",
       "      <td>10.8</td>\n",
       "      <td>31</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.86</td>\n",
       "      <td>30.03</td>\n",
       "      <td>6.3</td>\n",
       "      <td>27</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.67</td>\n",
       "      <td>29.84</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_nbr        date tmax tmin tavg depart dewpoint wetbulb heat cool  \\\n",
       "0            1  2012-01-01   52   31   42      M       36      40   23    0   \n",
       "1            1  2012-01-02   50   31   41      M       26      35   24    0   \n",
       "2            1  2012-01-03   32   11   22      M        4      18   43    0   \n",
       "3            1  2012-01-04   28    9   19      M       -1      14   46    0   \n",
       "4            1  2012-01-05   38   25   32      M       13      25   33    0   \n",
       "\n",
       "  sunrise sunset     codesum snowfall preciptotal stnpressure sealevel  \\\n",
       "0       -      -  RA FZFG BR        M        0.05       29.78    29.92   \n",
       "1       -      -                    M        0.01       29.44    29.62   \n",
       "2       -      -                    M        0.00       29.67    29.87   \n",
       "3       -      -                    M        0.00       29.86    30.03   \n",
       "4       -      -                    M        0.00       29.67    29.84   \n",
       "\n",
       "  resultspeed resultdir avgspeed  \n",
       "0         3.6        20      4.6  \n",
       "1         9.8        24     10.3  \n",
       "2        10.8        31     11.6  \n",
       "3         6.3        27      8.3  \n",
       "4         6.9        25      7.8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_train.reset_index(drop = True, inplace = True)\n",
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "set_tmax(weather_train)\n",
    "set_tmin(weather_train)\n",
    "set_tavg(weather_train)\n",
    "set_heat_cool(weather_train)\n",
    "merge_heat_cool(weather_train)\n",
    "# set_depart(weather_train)\n",
    "set_snowfall_preciptotal(weather_train)\n",
    "set_dewpoint(weather_train)\n",
    "set_wetbulb(weather_train)\n",
    "set_stnpressure(weather_train)\n",
    "set_sealevel(weather_train)\n",
    "set_resultspeed(weather_train)\n",
    "set_resultdir(weather_train)\n",
    "set_avgspeed(weather_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(len(weather_train)) :\n",
    "    if 'M' in weather_train.at[num, 'depart'] :\n",
    "        weather_train.set_value(num, 'depart', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_nbr', 'date', 'tmax', 'tmin', 'tavg', 'depart', 'dewpoint',\n",
       "       'wetbulb', 'heat', 'cool', 'sunrise', 'sunset', 'codesum', 'snowfall',\n",
       "       'preciptotal', 'stnpressure', 'sealevel', 'resultspeed', 'resultdir',\n",
       "       'avgspeed', 'heat_cool'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_train_drop = weather_train.drop(['heat', 'cool', 'sunrise', 'sunset', 'codesum'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>log_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store_nbr  item_nbr  units  log_units\n",
       "0  2012-01-01          1         1      0        0.0\n",
       "1  2012-01-01          1         2      0        0.0\n",
       "2  2012-01-01          1         3      0        0.0\n",
       "3  2012-01-01          1         4      0        0.0\n",
       "4  2012-01-01          1         5      0        0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(weather_train_drop, key, on = 'station_nbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.merge(df, train_new, on = ['date', 'store_nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tavg</th>\n",
       "      <th>depart</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>wetbulb</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>stnpressure</th>\n",
       "      <th>sealevel</th>\n",
       "      <th>resultspeed</th>\n",
       "      <th>resultdir</th>\n",
       "      <th>avgspeed</th>\n",
       "      <th>heat_cool</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>log_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.78</td>\n",
       "      <td>29.92</td>\n",
       "      <td>3.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.78</td>\n",
       "      <td>29.92</td>\n",
       "      <td>3.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.78</td>\n",
       "      <td>29.92</td>\n",
       "      <td>3.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.78</td>\n",
       "      <td>29.92</td>\n",
       "      <td>3.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.78</td>\n",
       "      <td>29.92</td>\n",
       "      <td>3.6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_nbr        date tmax tmin tavg depart dewpoint wetbulb snowfall  \\\n",
       "0            1  2012-01-01   52   31   42    NaN       36      40        0   \n",
       "1            1  2012-01-01   52   31   42    NaN       36      40        0   \n",
       "2            1  2012-01-01   52   31   42    NaN       36      40        0   \n",
       "3            1  2012-01-01   52   31   42    NaN       36      40        0   \n",
       "4            1  2012-01-01   52   31   42    NaN       36      40        0   \n",
       "\n",
       "  preciptotal stnpressure sealevel resultspeed resultdir avgspeed heat_cool  \\\n",
       "0        0.05       29.78    29.92         3.6        20      4.6       -23   \n",
       "1        0.05       29.78    29.92         3.6        20      4.6       -23   \n",
       "2        0.05       29.78    29.92         3.6        20      4.6       -23   \n",
       "3        0.05       29.78    29.92         3.6        20      4.6       -23   \n",
       "4        0.05       29.78    29.92         3.6        20      4.6       -23   \n",
       "\n",
       "   store_nbr  item_nbr  units  log_units  \n",
       "0          1         1      0        0.0  \n",
       "1          1         2      0        0.0  \n",
       "2          1         3      0        0.0  \n",
       "3          1         4      0        0.0  \n",
       "4          1         5      0        0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_nbr', 'date', 'tmax', 'tmin', 'tavg', 'depart', 'dewpoint',\n",
       "       'wetbulb', 'snowfall', 'preciptotal', 'stnpressure', 'sealevel',\n",
       "       'resultspeed', 'resultdir', 'avgspeed', 'heat_cool'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_train_drop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['station_nbr',\n",
       " 'date',\n",
       " 'tmax',\n",
       " 'tmin',\n",
       " 'tavg',\n",
       " 'depart',\n",
       " 'dewpoint',\n",
       " 'wetbulb',\n",
       " 'snowfall',\n",
       " 'preciptotal',\n",
       " 'stnpressure',\n",
       " 'sealevel',\n",
       " 'resultspeed',\n",
       " 'resultdir',\n",
       " 'avgspeed',\n",
       " 'heat_cool']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_col = list(weather_train_drop.columns)\n",
    "weather_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = ['station_nbr', 'item_nbr']\n",
    "weather_col = weather_col[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = ['C(station_nbr):C(item_nbr):{}'.format(weather)  for weather in weather_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_formula = \" + \".join(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C(station_nbr):C(item_nbr):tmax + C(station_nbr):C(item_nbr):tmin + C(station_nbr):C(item_nbr):tavg + C(station_nbr):C(item_nbr):depart + C(station_nbr):C(item_nbr):dewpoint + C(station_nbr):C(item_nbr):wetbulb + C(station_nbr):C(item_nbr):snowfall + C(station_nbr):C(item_nbr):preciptotal + C(station_nbr):C(item_nbr):stnpressure + C(station_nbr):C(item_nbr):sealevel + C(station_nbr):C(item_nbr):resultspeed + C(station_nbr):C(item_nbr):resultdir + C(station_nbr):C(item_nbr):avgspeed + C(station_nbr):C(item_nbr):heat_cool'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 'log_units ~ ' + '0 + '+ total_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log_units ~ 0 + C(station_nbr):C(item_nbr):tmax + C(station_nbr):C(item_nbr):tmin + C(station_nbr):C(item_nbr):tavg + C(station_nbr):C(item_nbr):depart + C(station_nbr):C(item_nbr):dewpoint + C(station_nbr):C(item_nbr):wetbulb + C(station_nbr):C(item_nbr):snowfall + C(station_nbr):C(item_nbr):preciptotal + C(station_nbr):C(item_nbr):stnpressure + C(station_nbr):C(item_nbr):sealevel + C(station_nbr):C(item_nbr):resultspeed + C(station_nbr):C(item_nbr):resultdir + C(station_nbr):C(item_nbr):avgspeed + C(station_nbr):C(item_nbr):heat_cool'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.sort_values(by = ['station_nbr', 'date', 'store_nbr', 'item_nbr'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-67430d74f879>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_formula\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[1;32m--> 155\u001b[1;33m                                   missing=missing)\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[1;32m---> 65\u001b[1;33m                                NA_action=na_action)\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m--> 310\u001b[1;33m                                       NA_action, return_type)\n\u001b[0m\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is missing required outcome variables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m--> 165\u001b[1;33m                                       NA_action)\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                                       \u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                                       NA_action)\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msubterm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubterms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                 for column_name in _subterm_column_names_iter(\n\u001b[1;32m--> 732\u001b[1;33m                         factor_infos, subterm):\n\u001b[0m\u001b[0;32m    733\u001b[0m                     \u001b[0mcolumn_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         design_infos.append(DesignInfo(column_names,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36m_subterm_column_names_iter\u001b[1;34m(factor_infos, subterm)\u001b[0m\n\u001b[0;32m    249\u001b[0m                 \u001b[0mcontrast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubterm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrast_matrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[0msuffix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_suffixes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 \u001b[0mname_pieces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname_pieces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;34m\"Intercept\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36mname\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = sm.OLS.from_formula(total, data = df_, missing = 'drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 dataframe별로 뒤에 붙는 숫자에 주의해야함\n",
    "- station_nbr 기준인지 store_nbr 기준인지..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr별 특징\n",
    "- no depart value : 1, 7, 8, 9, 10, 12, 13, 16, 17, 20\n",
    "    - drop??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 1\n",
    "- store_nbr == 1\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_1)\n",
    "set_tmin(weather_train_1)\n",
    "set_tavg(weather_train_1)\n",
    "set_heat_cool(weather_train_1)\n",
    "merge_heat_cool(weather_train_1)\n",
    "set_depart(weather_train_1)\n",
    "set_snowfall_preciptotal(weather_train_1)\n",
    "set_dewpoint(weather_train_1)\n",
    "set_wetbulb(weather_train_1)\n",
    "set_stnpressure(weather_train_1)\n",
    "set_sealevel(weather_train_1)\n",
    "set_resultspeed(weather_train_1)\n",
    "set_resultdir(weather_train_1)\n",
    "set_avgspeed(weather_train_1)\n",
    "\n",
    "# merged_1 = merge_weather_train(weather_train_1, train_new_1)\n",
    "item_nbr_list_1 = get_item_nbr(train_new_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_1 :\n",
    "    plt.subplot(len(item_nbr_list_1), 1, plotcount)\n",
    "    plt.scatter(x = merged_1['tmax'], y = merged_1[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(merged_1, x_vars = ['tmax', 'tmin', 'tavg'], y_vars = item_nbr_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_1_test = weather_train_1.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "train_new_1_pivot = train_new_1.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_1_pivot.loc[len(train_new_1)] = 0\n",
    "# train_new_1_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = train_new_1.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "train_new_1_pivot = pd.DataFrame(np.insert(train_new_1_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_1 :\n",
    "    dfX = sm.add_constant(weather_train_1_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_1_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear regression에서는 array형태 data type이 필요하다.. np.asarray\n",
    "# NaN값이 있으면 안되나벼..\n",
    "\n",
    "weather_train_1_test_array = np.asarray(weather_train_1_test)\n",
    "\n",
    "for num in item_nbr_list_1 :\n",
    "\n",
    "    model2 = LinearRegression().fit(weather_train_1_test_array, np.asarray(train_new_1_pivot[num]))\n",
    "\n",
    "    # model2.coef_\n",
    "    # model2.intercept_\n",
    "\n",
    "    predictions = model2.predict(np.asarray(weather_train_1_test_array))\n",
    "\n",
    "    plt.scatter(train_new_1_pivot[num], predictions)\n",
    "    # plt.xlabel(u\"실제 집값\")\n",
    "    # plt.ylabel(u\"집값 예측치\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  station_nbr == 2\n",
    "- store_nbr == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_2)\n",
    "set_tmin(weather_train_2)\n",
    "set_tavg(weather_train_2)\n",
    "set_heat_cool(weather_train_2)\n",
    "merge_heat_cool(weather_train_2)\n",
    "set_depart(weather_train_2)\n",
    "set_snowfall_preciptotal(weather_train_2)\n",
    "set_dewpoint(weather_train_2)\n",
    "set_wetbulb(weather_train_2)\n",
    "set_stnpressure(weather_train_2)\n",
    "set_sealevel(weather_train_2)\n",
    "set_resultspeed(weather_train_2)\n",
    "set_resultdir(weather_train_2)\n",
    "set_avgspeed(weather_train_2)\n",
    "\n",
    "# merged_2 = merge_weather_train(weather_train_2, train_new_16)\n",
    "item_nbr_list_2 = get_item_nbr(train_new_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_2 :\n",
    "    plt.subplot(len(item_nbr_list_2), 1, plotcount)\n",
    "    plt.scatter(x = merged_2['tmax'], y = merged_2[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_2_test = weather_train_2.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "train_new_16_pivot = train_new_16.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_16_pivot.loc[len(train_new_16)] = 0\n",
    "# train_new_16_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "train_new_16_pivot = pd.DataFrame(np.insert(train_new_16_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_2 :\n",
    "    dfX = sm.add_constant(weather_train_1_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_16_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 3\n",
    "- store_nbr == 21, 29, 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_21, train_new_29, train_new_33])\n",
    "\n",
    "set_tmax(weather_train_3)\n",
    "set_tmin(weather_train_3)\n",
    "set_tavg(weather_train_3)\n",
    "set_heat_cool(weather_train_3)\n",
    "merge_heat_cool(weather_train_3)\n",
    "set_depart(weather_train_3)\n",
    "set_snowfall_preciptotal(weather_train_3)\n",
    "set_dewpoint(weather_train_3)\n",
    "set_wetbulb(weather_train_3)\n",
    "set_stnpressure(weather_train_3)\n",
    "set_sealevel(weather_train_3)\n",
    "set_resultspeed(weather_train_3)\n",
    "set_resultdir(weather_train_3)\n",
    "set_avgspeed(weather_train_3)\n",
    "\n",
    "# merged_3 = merge_weather_train(weather_train_3, result)\n",
    "item_nbr_list_3 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_3 :\n",
    "    plt.subplot(len(item_nbr_list_3), 1, plotcount)\n",
    "    plt.scatter(x = merged_3['tmax'], y = merged_3[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_3_test = weather_train_3.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(train_new_1)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_3 :\n",
    "    dfX = sm.add_constant(weather_train_3_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 4\n",
    "- store_nbr == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_4)\n",
    "set_tmin(weather_train_4)\n",
    "set_tavg(weather_train_4)\n",
    "set_heat_cool(weather_train_4)\n",
    "merge_heat_cool(weather_train_4)\n",
    "set_depart(weather_train_4)\n",
    "set_snowfall_preciptotal(weather_train_4)\n",
    "set_dewpoint(weather_train_4)\n",
    "set_wetbulb(weather_train_4)\n",
    "set_stnpressure(weather_train_4)\n",
    "set_sealevel(weather_train_4)\n",
    "set_resultspeed(weather_train_4)\n",
    "set_resultdir(weather_train_4)\n",
    "set_avgspeed(weather_train_4)\n",
    "\n",
    "# merged_4 = merge_weather_train(weather_train_4, train_new_8)\n",
    "item_nbr_list_4 = get_item_nbr(train_new_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_4 :\n",
    "    plt.subplot(len(item_nbr_list_4), 1, plotcount)\n",
    "    plt.scatter(x = merged_4['tmax'], y = merged_4[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_4_test = weather_train_4.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "train_new_8_pivot = train_new_8.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_8_pivot.loc[len(train_new_8)] = 0\n",
    "# train_new_8_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "train_new_8_pivot = pd.DataFrame(np.insert(train_new_8_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_4 :\n",
    "    dfX = sm.add_constant(weather_train_4_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_8_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 5\n",
    "- store_nbr == 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 여긴 좀 고민할 필요가 있음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 6\n",
    "- store_nbr == 7, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_7, train_new_13])\n",
    "\n",
    "set_tmax(weather_train_6)\n",
    "set_tmin(weather_train_6)\n",
    "set_tavg(weather_train_6)\n",
    "set_heat_cool(weather_train_6)\n",
    "merge_heat_cool(weather_train_6)\n",
    "set_depart(weather_train_6)\n",
    "set_snowfall_preciptotal(weather_train_6)\n",
    "set_dewpoint(weather_train_6)\n",
    "set_wetbulb(weather_train_6)\n",
    "set_stnpressure(weather_train_6)\n",
    "set_sealevel(weather_train_6)\n",
    "set_resultspeed(weather_train_6)\n",
    "set_resultdir(weather_train_6)\n",
    "set_avgspeed(weather_train_6)\n",
    "\n",
    "# merged_6 = merge_weather_train(weather_train_6, result)\n",
    "item_nbr_list_6 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_6 :\n",
    "    plt.subplot(len(item_nbr_list_6), 1, plotcount)\n",
    "    plt.scatter(x = merged_6['tmax'], y = merged_6[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_6_test = weather_train_6.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_6 :\n",
    "    dfX = sm.add_constant(weather_train_6_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 7\n",
    "- store_nbr == 3, 20, 28\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_3, train_new_20, train_new_28])\n",
    "\n",
    "set_tmax(weather_train_7)\n",
    "set_tmin(weather_train_7)\n",
    "set_tavg(weather_train_7)\n",
    "set_heat_cool(weather_train_7)\n",
    "merge_heat_cool(weather_train_7)\n",
    "set_depart(weather_train_7)\n",
    "set_snowfall_preciptotal(weather_train_7)\n",
    "set_dewpoint(weather_train_7)\n",
    "set_wetbulb(weather_train_7)\n",
    "set_stnpressure(weather_train_7)\n",
    "set_sealevel(weather_train_7)\n",
    "set_resultspeed(weather_train_7)\n",
    "set_resultdir(weather_train_7)\n",
    "set_avgspeed(weather_train_7)\n",
    "\n",
    "# merged_7 = merge_weather_train(weather_train_7, result)\n",
    "item_nbr_list_7 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_7 :\n",
    "    plt.subplot(len(item_nbr_list_7), 1, plotcount)\n",
    "    plt.scatter(x = merged_7['tmax'], y = merged_7[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_7_test = weather_train_7.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_7 :\n",
    "    dfX = sm.add_constant(weather_train_7_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 8\n",
    "- store_nbr == 39\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_8)\n",
    "set_tmin(weather_train_8)\n",
    "set_tavg(weather_train_8)\n",
    "set_heat_cool(weather_train_8)\n",
    "merge_heat_cool(weather_train_8)\n",
    "set_depart(weather_train_8)\n",
    "set_snowfall_preciptotal(weather_train_8)\n",
    "set_dewpoint(weather_train_8)\n",
    "set_wetbulb(weather_train_8)\n",
    "set_stnpressure(weather_train_8)\n",
    "set_sealevel(weather_train_8)\n",
    "set_resultspeed(weather_train_8)\n",
    "set_resultdir(weather_train_8)\n",
    "set_avgspeed(weather_train_8)\n",
    "\n",
    "# merged_8 = merge_weather_train(weather_train_8, train_new_39)\n",
    "item_nbr_list_8 = get_item_nbr(train_new_39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_8 :\n",
    "    plt.subplot(len(item_nbr_list_8), 1, plotcount)\n",
    "    plt.scatter(x = merged_8['tmax'], y = merged_8[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_8_test = weather_train_8.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum',\n",
    "                                             'heat', 'cool', 'sealevel'], axis = 1)\n",
    "\n",
    "train_new_39_pivot = train_new_39.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_39_pivot.loc[len(train_new_39)] = 0\n",
    "# train_new_39_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = train_new_39.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "train_new_39_pivot = pd.DataFrame(np.insert(train_new_39_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_8 :\n",
    "    dfX = sm.add_constant(weather_train_8_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_39_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 9\n",
    "- store_nbr == 4, 24\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_4, train_new_24])\n",
    "\n",
    "set_tmax(weather_train_9)\n",
    "set_tmin(weather_train_9)\n",
    "set_tavg(weather_train_9)\n",
    "set_heat_cool(weather_train_9)\n",
    "merge_heat_cool(weather_train_9)\n",
    "set_depart(weather_train_9)\n",
    "set_snowfall_preciptotal(weather_train_9)\n",
    "set_dewpoint(weather_train_9)\n",
    "set_wetbulb(weather_train_9)\n",
    "set_stnpressure(weather_train_9)\n",
    "set_sealevel(weather_train_9)\n",
    "set_resultspeed(weather_train_9)\n",
    "set_resultdir(weather_train_9)\n",
    "set_avgspeed(weather_train_9)\n",
    "\n",
    "# merged_9 = merge_weather_train(weather_train_9, result)\n",
    "item_nbr_list_9 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_9 :\n",
    "    plt.subplot(len(item_nbr_list_9), 1, plotcount)\n",
    "    plt.scatter(x = merged_9['tmax'], y = merged_9[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_9_test = weather_train_9.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_9 :\n",
    "    dfX = sm.add_constant(weather_train_9_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 10\n",
    "- store_nbr == 11, 22, 27\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_11, train_new_22, train_new_27])\n",
    "\n",
    "set_tmax(weather_train_10)\n",
    "set_tmin(weather_train_10)\n",
    "set_tavg(weather_train_10)\n",
    "set_heat_cool(weather_train_10)\n",
    "merge_heat_cool(weather_train_10)\n",
    "set_depart(weather_train_10)\n",
    "set_snowfall_preciptotal(weather_train_10)\n",
    "set_dewpoint(weather_train_10)\n",
    "set_wetbulb(weather_train_10)\n",
    "set_stnpressure(weather_train_10)\n",
    "set_sealevel(weather_train_10)\n",
    "set_resultspeed(weather_train_10)\n",
    "set_resultdir(weather_train_10)\n",
    "set_avgspeed(weather_train_10)\n",
    "\n",
    "# merged_10 = merge_weather_train(weather_train_10, result)\n",
    "item_nbr_list_10 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_10 :\n",
    "    plt.subplot(len(item_nbr_list_10), 1, plotcount)\n",
    "    plt.scatter(x = merged_10['tmax'], y = merged_10[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_10_test = weather_train_10.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_10 :\n",
    "    dfX = sm.add_constant(weather_train_10_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 11\n",
    "- store_nbr == 12, 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_12, train_new_43])\n",
    "\n",
    "set_tmax(weather_train_11)\n",
    "set_tmin(weather_train_11)\n",
    "set_tavg(weather_train_11)\n",
    "set_heat_cool(weather_train_11)\n",
    "merge_heat_cool(weather_train_11)\n",
    "set_depart(weather_train_11)\n",
    "set_snowfall_preciptotal(weather_train_11)\n",
    "set_dewpoint(weather_train_11)\n",
    "set_wetbulb(weather_train_11)\n",
    "set_stnpressure(weather_train_11)\n",
    "set_sealevel(weather_train_11)\n",
    "set_resultspeed(weather_train_11)\n",
    "set_resultdir(weather_train_11)\n",
    "set_avgspeed(weather_train_11)\n",
    "\n",
    "# merged_11 = merge_weather_train(weather_train_11, result)\n",
    "item_nbr_list_11 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_11 :\n",
    "    plt.subplot(len(item_nbr_list_11), 1, plotcount)\n",
    "    plt.scatter(x = merged_11['tmax'], y = merged_11[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_11_test = weather_train_11.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_11 :\n",
    "    dfX = sm.add_constant(weather_train_11_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 12\n",
    "- store_nbr == 5, 10, 41, 44\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_5, train_new_10, train_new_41, train_new_44])\n",
    "\n",
    "set_tmax(weather_train_12)\n",
    "set_tmin(weather_train_12)\n",
    "set_tavg(weather_train_12)\n",
    "set_heat_cool(weather_train_12)\n",
    "merge_heat_cool(weather_train_12)\n",
    "set_depart(weather_train_12)\n",
    "set_snowfall_preciptotal(weather_train_12)\n",
    "set_dewpoint(weather_train_12)\n",
    "set_wetbulb(weather_train_12)\n",
    "set_stnpressure(weather_train_12)\n",
    "set_sealevel(weather_train_12)\n",
    "set_resultspeed(weather_train_12)\n",
    "set_resultdir(weather_train_12)\n",
    "set_avgspeed(weather_train_12)\n",
    "\n",
    "# merged_12 = merge_weather_train(weather_train_12, result)\n",
    "item_nbr_list_12 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_12 :\n",
    "    plt.subplot(len(item_nbr_list_12), 1, plotcount)\n",
    "    plt.scatter(x = merged_12['tmax'], y = merged_12[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_12_test = weather_train_12.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_12 :\n",
    "    dfX = sm.add_constant(weather_train_12_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 13\n",
    "- store_nbr == 15, 25, 32, 37, 40\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_15, train_new_25, train_new_32, train_new_37, train_new_40])\n",
    "\n",
    "set_tmax(weather_train_13)\n",
    "set_tmin(weather_train_13)\n",
    "set_tavg(weather_train_13)\n",
    "set_heat_cool(weather_train_13)\n",
    "merge_heat_cool(weather_train_13)\n",
    "set_depart(weather_train_13)\n",
    "set_snowfall_preciptotal(weather_train_13)\n",
    "set_dewpoint(weather_train_13)\n",
    "set_wetbulb(weather_train_13)\n",
    "set_stnpressure(weather_train_13)\n",
    "set_sealevel(weather_train_13)\n",
    "set_resultspeed(weather_train_13)\n",
    "set_resultdir(weather_train_13)\n",
    "set_avgspeed(weather_train_13)\n",
    "\n",
    "# merged_13 = merge_weather_train(weather_train_13, result)\n",
    "item_nbr_list_13 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_13 :\n",
    "    plt.subplot(len(item_nbr_list_13), 1, plotcount)\n",
    "    plt.scatter(x = merged_13['tmax'], y = merged_13[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_13_test = weather_train_13.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_13 :\n",
    "    dfX = sm.add_constant(weather_train_13_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 14\n",
    "- store_nbr == 2, 6, 38, 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_2, train_new_6, train_new_38, train_new_42])\n",
    "\n",
    "set_tmax(weather_train_14)\n",
    "set_tmin(weather_train_14)\n",
    "set_tavg(weather_train_14)\n",
    "set_heat_cool(weather_train_14)\n",
    "merge_heat_cool(weather_train_14)\n",
    "set_depart(weather_train_14)\n",
    "set_snowfall_preciptotal(weather_train_14)\n",
    "set_dewpoint(weather_train_14)\n",
    "set_wetbulb(weather_train_14)\n",
    "set_stnpressure(weather_train_14)\n",
    "set_sealevel(weather_train_14)\n",
    "set_resultspeed(weather_train_14)\n",
    "set_resultdir(weather_train_14)\n",
    "set_avgspeed(weather_train_14)\n",
    "\n",
    "# merged_14 = merge_weather_train(weather_train_14, result)\n",
    "item_nbr_list_14 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_14 :\n",
    "    plt.subplot(len(item_nbr_list_14), 1, plotcount)\n",
    "    plt.scatter(x = merged_14['tmax'], y = merged_14[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_14_test = weather_train_14.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_14 :\n",
    "    dfX = sm.add_constant(weather_train_14_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 15\n",
    "- store_nbr == 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_15)\n",
    "set_tmin(weather_train_15)\n",
    "set_tavg(weather_train_15)\n",
    "set_heat_cool(weather_train_15)\n",
    "merge_heat_cool(weather_train_15)\n",
    "set_depart(weather_train_15)\n",
    "set_snowfall_preciptotal(weather_train_15)\n",
    "set_dewpoint(weather_train_15)\n",
    "set_wetbulb(weather_train_15)\n",
    "set_stnpressure(weather_train_15)\n",
    "set_sealevel(weather_train_15)\n",
    "set_resultspeed(weather_train_15)\n",
    "set_resultdir(weather_train_15)\n",
    "set_avgspeed(weather_train_15)\n",
    "\n",
    "# merged_15 = merge_weather_train(weather_train_15, train_new_19)\n",
    "item_nbr_list_15 = get_item_nbr(train_new_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_15 :\n",
    "    plt.subplot(len(item_nbr_list_15), 1, plotcount)\n",
    "    plt.scatter(x = merged_15['tmax'], y = merged_15[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_15_test = weather_train_15.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "train_new_19_pivot = train_new_19.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_19_pivot.loc[len(train_new_19)] = 0\n",
    "# train_new_19_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = train_new_19.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "train_new_19_pivot = pd.DataFrame(np.insert(train_new_19_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_15 :\n",
    "    dfX = sm.add_constant(weather_train_15_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_19_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 16\n",
    "- store_nbr == 14, 45\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_14, train_new_45])\n",
    "\n",
    "set_tmax(weather_train_16)\n",
    "set_tmin(weather_train_16)\n",
    "set_tavg(weather_train_16)\n",
    "set_heat_cool(weather_train_16)\n",
    "merge_heat_cool(weather_train_16)\n",
    "set_depart(weather_train_16)\n",
    "set_snowfall_preciptotal(weather_train_16)\n",
    "set_dewpoint(weather_train_16)\n",
    "set_wetbulb(weather_train_16)\n",
    "set_stnpressure(weather_train_16)\n",
    "set_sealevel(weather_train_16)\n",
    "set_resultspeed(weather_train_16)\n",
    "set_resultdir(weather_train_16)\n",
    "set_avgspeed(weather_train_16)\n",
    "\n",
    "# merged_16 = merge_weather_train(weather_train_16, result)\n",
    "item_nbr_list_16 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_16 :\n",
    "    plt.subplot(len(item_nbr_list_16), 1, plotcount)\n",
    "    plt.scatter(x = merged_16['tmax'], y = merged_16[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_16_test = weather_train_16.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_16 :\n",
    "    dfX = sm.add_constant(weather_train_16_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 17\n",
    "- store_nbr == 9, 18, 23, 26, 31, 34\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([train_new_9, train_new_18, train_new_23, train_new_26, train_new_31, train_new_34])\n",
    "\n",
    "set_tmax(weather_train_17)\n",
    "set_tmin(weather_train_17)\n",
    "set_tavg(weather_train_17)\n",
    "set_heat_cool(weather_train_17)\n",
    "merge_heat_cool(weather_train_17)\n",
    "set_depart(weather_train_17)\n",
    "set_snowfall_preciptotal(weather_train_17)\n",
    "set_dewpoint(weather_train_17)\n",
    "set_wetbulb(weather_train_17)\n",
    "set_stnpressure(weather_train_17)\n",
    "set_sealevel(weather_train_17)\n",
    "set_resultspeed(weather_train_17)\n",
    "set_resultdir(weather_train_17)\n",
    "set_avgspeed(weather_train_17)\n",
    "\n",
    "# merged_17 = merge_weather_train(weather_train_17, result)\n",
    "item_nbr_list_17 = get_item_nbr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_17 :\n",
    "    plt.subplot(len(item_nbr_list_17), 1, plotcount)\n",
    "    plt.scatter(x = merged_17['tmax'], y = merged_17[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_17_test = weather_train_17.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "result_pivot = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# result_pivot.loc[len(result)] = 0\n",
    "# result_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = result.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "result_pivot = pd.DataFrame(np.insert(result_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_17 :\n",
    "    dfX = sm.add_constant(weather_train_17_test)\n",
    "    dfy = pd.DataFrame(np.asarray(result_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 18\n",
    "- store_nbr == 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_18)\n",
    "set_tmin(weather_train_18)\n",
    "set_tavg(weather_train_18)\n",
    "set_heat_cool(weather_train_18)\n",
    "merge_heat_cool(weather_train_18)\n",
    "set_depart(weather_train_18)\n",
    "set_snowfall_preciptotal(weather_train_18)\n",
    "set_dewpoint(weather_train_18)\n",
    "set_wetbulb(weather_train_18)\n",
    "set_stnpressure(weather_train_18)\n",
    "set_sealevel(weather_train_18)\n",
    "set_resultspeed(weather_train_18)\n",
    "set_resultdir(weather_train_18)\n",
    "set_avgspeed(weather_train_18)\n",
    "\n",
    "# merged_18 = merge_weather_train(weather_train_18, train_new_36)\n",
    "item_nbr_list_18 = get_item_nbr(train_new_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_18 :\n",
    "    plt.subplot(len(item_nbr_list_18), 1, plotcount)\n",
    "    plt.scatter(x = merged_18['tmax'], y = merged_18[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_18_test = weather_train_18.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "train_new_36_pivot = train_new_36.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_36_pivot.loc[len(train_new_36)] = 0\n",
    "# train_new_36_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = train_new_36.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "train_new_36_pivot = pd.DataFrame(np.insert(train_new_36_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_18 :\n",
    "    dfX = sm.add_constant(weather_train_18_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_36_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 19\n",
    "- store_nbr == 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_19)\n",
    "set_tmin(weather_train_19)\n",
    "set_tavg(weather_train_19)\n",
    "set_heat_cool(weather_train_19)\n",
    "merge_heat_cool(weather_train_19)\n",
    "set_depart(weather_train_19)\n",
    "set_snowfall_preciptotal(weather_train_19)\n",
    "set_dewpoint(weather_train_19)\n",
    "set_wetbulb(weather_train_19)\n",
    "set_stnpressure(weather_train_19)\n",
    "set_sealevel(weather_train_19)\n",
    "set_resultspeed(weather_train_19)\n",
    "set_resultdir(weather_train_19)\n",
    "set_avgspeed(weather_train_19)\n",
    "\n",
    "# merged_19 = merge_weather_train(weather_train_19, train_new_30)\n",
    "item_nbr_list_19 = get_item_nbr(train_new_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_19 :\n",
    "    plt.subplot(len(item_nbr_list_19), 1, plotcount)\n",
    "    plt.scatter(x = merged_19['tmax'], y = merged_19[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_19_test = weather_train_19.drop(['station_nbr', 'date', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "train_new_30_pivot = train_new_30.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_30_pivot.loc[len(train_new_30)] = 0\n",
    "# train_new_30_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = train_new_30.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "train_new_30_pivot = pd.DataFrame(np.insert(train_new_30_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_19 :\n",
    "    dfX = sm.add_constant(weather_train_19_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_30_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### station_nbr == 20\n",
    "- store_nbr == 17\n",
    "- no depart value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_tmax(weather_train_20)\n",
    "set_tmin(weather_train_20)\n",
    "set_tavg(weather_train_20)\n",
    "set_heat_cool(weather_train_20)\n",
    "merge_heat_cool(weather_train_20)\n",
    "set_depart(weather_train_20)\n",
    "set_snowfall_preciptotal(weather_train_20)\n",
    "set_dewpoint(weather_train_20)\n",
    "set_wetbulb(weather_train_20)\n",
    "set_stnpressure(weather_train_20)\n",
    "set_sealevel(weather_train_20)\n",
    "set_resultspeed(weather_train_20)\n",
    "set_resultdir(weather_train_20)\n",
    "set_avgspeed(weather_train_20)\n",
    "\n",
    "# merged_20 = merge_weather_train(weather_train_20, train_new_17)\n",
    "item_nbr_list_20 = get_item_nbr(train_new_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plotcount = 1\n",
    "for num in item_nbr_list_20 :\n",
    "    plt.subplot(len(item_nbr_list_20), 1, plotcount)\n",
    "    plt.scatter(x = merged_20['tmax'], y = merged_20[num]) # x에 들어가는 column을 바꿔가며 관계시각화 가능..pairplot은 왜 안되지 ㅅㅂ\n",
    "    \n",
    "    plt.ylabel('log_units')\n",
    "#     plt.ylabel('log_units of item_nbr == {}'.format(num))\n",
    "\n",
    "    plt.title('item_nbr == {}'.format(num))\n",
    "        \n",
    "    plotcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_20_test = weather_train_20.drop(['station_nbr', 'date', 'depart', 'sunrise', 'sunset', 'codesum', 'heat', 'cool'], axis = 1)\n",
    "\n",
    "train_new_17_pivot = train_new_17.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "# train_new_17_pivot.loc[len(train_new_17)] = 0\n",
    "# train_new_17_pivot.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# test = train_new_17.pivot_table(values = 'log_units', index = ['date'], columns = ['item_nbr'])\n",
    "train_new_17_pivot = pd.DataFrame(np.insert(train_new_17_pivot.values, 359, values = 0, axis = 0))\n",
    "\n",
    "for num in item_nbr_list_20 :\n",
    "    dfX = sm.add_constant(weather_train_20_test)\n",
    "    dfy = pd.DataFrame(np.asarray(train_new_17_pivot[num - 1]), columns=[\"item_nbr == {}\".format(num)])\n",
    "\n",
    "    model = sm.OLS(dfy.astype(float), dfX.astype(float), missing = 'drop')\n",
    "    result_model = model.fit()\n",
    "    print(result_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression, OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = merged_1.drop(['station_nbr', 'date', 'depart', 'dewpoint', 'wetbulb', 'heat', 'cool', 'snowfall',\n",
    "                    'preciptotal', 'stnpressure', 'sealevel', 'codesum', 'sunrise', 'sunset', 'resultspeed',\n",
    "                    'resultdir', 'avgspeed', 'tavg', 'heat/cool'], axis = 1)\n",
    "tmp_data = tmp.drop([9, 28, 40, 51, 89, 93, 99], axis = 1) # tmax, tmin, tavg, heat/cool column만 있음..일단 이렇게만..\n",
    "tmp_target = tmp[9] # item_nbr == 9 인 case에 대해서만 우선 해보자\n",
    "tmp_data_array = np.asarray(weather_train_1)\n",
    "tmp_target_array = np.asarray(tmp_target)\n",
    "tmp_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear regression에서는 array형태 data type이 필요하다.. np.asarray\n",
    "\n",
    "model_tmp = LinearRegression().fit(tmp_data_array, tmp_target_array)\n",
    "\n",
    "# model_tmp.coef_\n",
    "# model_tmp.intercept_\n",
    "\n",
    "predictions = model_tmp.predict(tmp_data_array)\n",
    "\n",
    "plt.scatter(tmp_target_array, predictions)\n",
    "# plt.xlabel(u\"실제 집값\")\n",
    "# plt.ylabel(u\"집값 예측치\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dep. Variable : Which variable is the response in the model\n",
    "\n",
    "- Model : What model you are using in the fit\n",
    "\n",
    "- Method : How the parameters of the model were calculated\n",
    "\n",
    "- No. Observations : The number of observations (examples)\n",
    "- DF Residuals : Degrees of freedom of the residuals. Number of observations – number of parameters\n",
    "- DF Model : Number of parameters in the model (not including the constant term if present)\n",
    "\n",
    "#### The right part of the first table shows the goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second table reports for each of the coefficients\n",
    "\n",
    "- R-squared : The coefficient of determination. A statistical measure of how well the regression line approximates the real data points\n",
    "    \n",
    "- Adj. R-squared : The above value adjusted based on the number of observations and the degrees-of-freedom of the residuals\n",
    "- F-statistic : A measure how significant the fit is. The mean squared error of the model divided by the mean squared error of the residuals\n",
    "- Prob (F-statistic) : The probability that you would get the above statistic, given the null hypothesis that they are unrelated\n",
    "- Log-likelihood : The log of the likelihood function.\n",
    "- AIC : The Akaike Information Criterion. Adjusts the log-likelihood based on the number of observations and the complexity of the model.\n",
    "- BIC : The Bayesian Information Criterion. Similar to the AIC, but has a higher penalty for models with more parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfy_new = result_tmp2.predict(dfX)\n",
    "\n",
    "plt.scatter(dfy, dfy_new)\n",
    "# plt.xlabel(u\"실제 집값\")\n",
    "# plt.ylabel(u\"집값 예측치\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
